{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caaad009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from Water_Blance_Model import mYWBMnlS, abcdnlS, DWBMnlS\n",
    "from Rewrite_Func import nash_sutcliffe_efficiency, relative_error, kling_gupta_efficiency\n",
    "from numba import float64, njit\n",
    "from numba.experimental import jitclass\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.ndimage import median_filter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba576d4",
   "metadata": {},
   "source": [
    "# 定义流域信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c956cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取流域信息\n",
    "basin_info      = pd.read_excel('../../Data/Basin_Selection/All_Selected_Basins.xlsx')\n",
    "basin_list      = basin_info['stat_num'].astype(str)\n",
    "cali_start_list = basin_info['cali_start']\n",
    "cali_end_list   = basin_info['cali_end']\n",
    "vali_start_list = basin_info['vali_start']\n",
    "vali_end_list   = basin_info['vali_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec2a9f7",
   "metadata": {},
   "source": [
    "# 定义数据读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fa6e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集总式模型数据读取\n",
    "def get_data_lumped(basin, basin_idx):\n",
    "    filepath = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    hc_data = pd.read_csv(filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start = pd.to_datetime(f\"{str(cali_start_list[basin_idx])}-01-01\")\n",
    "    cali_end   = pd.to_datetime(f\"{str(cali_end_list[basin_idx])}-12-31\")\n",
    "    vali_start = pd.to_datetime(f\"{str(vali_start_list[basin_idx])}-01-01\")\n",
    "    vali_end   = pd.to_datetime(f\"{str(vali_end_list[basin_idx])}-12-31\")\n",
    "\n",
    "    cali_data = hc_data.loc[cali_start : cali_end]\n",
    "    vali_data = hc_data.loc[vali_start : vali_end]\n",
    "\n",
    "    x_cali = cali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].to_numpy()\n",
    "    y_cali = cali_data['RUN'].to_numpy()\n",
    "    x_vali = vali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].to_numpy()\n",
    "    y_vali = vali_data['RUN'].to_numpy()\n",
    "    return x_cali, y_cali, x_vali, y_vali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8503909f",
   "metadata": {},
   "source": [
    "# 获取流域属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df019fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basin_Properties = pd.read_csv(\"../../Data/Properties/Basin_Properties.txt\", sep = '\\t', header=0, index_col='stat_num')\n",
    "source_properties = Basin_Properties[['Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e188ab",
   "metadata": {},
   "source": [
    "# 机器学习回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41edfe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(basin_properties_scaled, params):\n",
    "    # 初始化并训练模型\n",
    "    rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators      = 100, \n",
    "                                                          max_depth         = 10,\n",
    "                                                          min_samples_split = 5,\n",
    "                                                          min_samples_leaf  = 2,\n",
    "                                                          random_state      = 42,\n",
    "                                                          n_jobs            = -1), n_jobs=-1)\n",
    "    rf_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return rf_model\n",
    "\n",
    "def train_svm(basin_properties_scaled, params): \n",
    "    # 初始化并训练模型\n",
    "    svr_model = MultiOutputRegressor(SVR(kernel     = 'rbf',\n",
    "                                         C          = 100,\n",
    "                                         epsilon    = 0.01,\n",
    "                                         gamma      = 0.1), n_jobs=-1)\n",
    "    svr_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return svr_model\n",
    "\n",
    "def train_xgboost(basin_properties_scaled, params):\n",
    "    # 初始化并训练模型\n",
    "    xgb_model = MultiOutputRegressor(XGBRegressor(n_estimators      = 100,\n",
    "                                                  learning_rate     = 0.1,\n",
    "                                                  max_depth         = 6,\n",
    "                                                  min_child_weight  = 3,\n",
    "                                                  gamma             = 0.1,\n",
    "                                                  colsample_bytree  = 0.8,\n",
    "                                                  subsample         = 0.8,\n",
    "                                                  reg_alpha         = 0.1,\n",
    "                                                  random_state      = 42,\n",
    "                                                  n_jobs            = -1), n_jobs=-1)\n",
    "    xgb_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return xgb_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3165acdf",
   "metadata": {},
   "source": [
    "# 获取模型率定权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70bb6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = pd.read_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRA.txt\", sep=\"\\t\", index_col='stat_num')[['r_w_YM', 'r_w_AM', 'r_w_DM']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35007f5",
   "metadata": {},
   "source": [
    "# 循环每个流域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40b754e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing basin 1749550 (50/2003)\n"
     ]
    }
   ],
   "source": [
    "pred_weight_rf  = pd.DataFrame(index=basin_list, columns=['r_w_YM', 'r_w_AM', 'r_w_DM'])\n",
    "pred_weight_svr = pd.DataFrame(index=basin_list, columns=['r_w_YM', 'r_w_AM', 'r_w_DM'])\n",
    "pred_weight_xgb = pd.DataFrame(index=basin_list, columns=['r_w_YM', 'r_w_AM', 'r_w_DM'])\n",
    "\n",
    "b = 49\n",
    "basin = basin_list[b]\n",
    "print(f\"Processing basin {basin} ({b+1}/{len(basin_list)})\")\n",
    "\n",
    "X_train = np.vstack([source_properties[:b], source_properties[b+1:]])\n",
    "y_train = np.vstack([sim_results[:b], sim_results[b+1:]])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "\n",
    "# 获取当前流域属性\n",
    "target_properties = Basin_Properties.loc[basin, ['Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']].values.reshape(1, -1)\n",
    "target_properties_scaled = scaler.transform(target_properties)\n",
    "\n",
    "# 训练并预测随机森林模型\n",
    "rf_model  = train_random_forest(X_train_scaled, y_train)\n",
    "svr_model = train_svm(X_train_scaled, y_train)\n",
    "xgb_model = train_xgboost(X_train_scaled, y_train)\n",
    "\n",
    "rf_pred_scaled  = rf_model.predict(target_properties_scaled)[0]\n",
    "svr_pred_scaled = svr_model.predict(target_properties_scaled)[0]\n",
    "xgb_pred_scaled = xgb_model.predict(target_properties_scaled)[0]\n",
    "\n",
    "rf_pred  = y_scaler.inverse_transform(rf_pred_scaled.reshape(1, -1))\n",
    "svr_pred = y_scaler.inverse_transform(svr_pred_scaled.reshape(1, -1))\n",
    "xgb_pred = y_scaler.inverse_transform(xgb_pred_scaled.reshape(1, -1))\n",
    "\n",
    "# # 归一化，确保和为1\n",
    "# rf_pred  = np.clip(rf_pred, 0, None)\n",
    "# svr_pred = np.clip(svr_pred, 0, None)\n",
    "# xgb_pred = np.clip(xgb_pred, 0, None)\n",
    "# rf_pred  = rf_pred / np.sum(rf_pred)\n",
    "# svr_pred = svr_pred / np.sum(svr_pred)\n",
    "# xgb_pred = xgb_pred / np.sum(xgb_pred)\n",
    "\n",
    "pred_weight_rf.loc[basin]  = rf_pred\n",
    "pred_weight_svr.loc[basin] = svr_pred\n",
    "pred_weight_xgb.loc[basin] = xgb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93566851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r_w_YM</th>\n",
       "      <th>r_w_AM</th>\n",
       "      <th>r_w_DM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stat_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ZM_0000050</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM_0000053</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZM_0000043</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD_0000003</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD_0000002</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU_0001056</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU_0001063</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU_0001087</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU_0001127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AU_0001128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2003 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           r_w_YM r_w_AM r_w_DM\n",
       "stat_num                       \n",
       "ZM_0000050    NaN    NaN    NaN\n",
       "ZM_0000053    NaN    NaN    NaN\n",
       "ZM_0000043    NaN    NaN    NaN\n",
       "CD_0000003    NaN    NaN    NaN\n",
       "CD_0000002    NaN    NaN    NaN\n",
       "...           ...    ...    ...\n",
       "AU_0001056    NaN    NaN    NaN\n",
       "AU_0001063    NaN    NaN    NaN\n",
       "AU_0001087    NaN    NaN    NaN\n",
       "AU_0001127    NaN    NaN    NaN\n",
       "AU_0001128    NaN    NaN    NaN\n",
       "\n",
       "[2003 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_weight_rf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
