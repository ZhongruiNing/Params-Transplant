{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1dadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from Water_Blance_Model import mYWBMnlS, abcdnlS, DWBMnlS, abcdnlS_RE, DWBMnlS_RE, mYWBMnlS_RE\n",
    "from Rewrite_Func import nash_sutcliffe_efficiency, relative_error, kling_gupta_efficiency\n",
    "from numba import float64, njit\n",
    "from numba.experimental import jitclass\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from scipy.ndimage import median_filter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840127cc",
   "metadata": {},
   "source": [
    "# 定义流域信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50f27844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取流域信息\n",
    "basin_info      = pd.read_excel('../../Data/Basin_Selection/All_Selected_Basins.xlsx')\n",
    "basin_list      = basin_info['stat_num']\n",
    "cali_start_list = basin_info['cali_start']\n",
    "cali_end_list   = basin_info['cali_end']\n",
    "vali_start_list = basin_info['vali_start']\n",
    "vali_end_list   = basin_info['vali_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55e32a",
   "metadata": {},
   "source": [
    "# 定义数据读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c498b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集总式模型数据读取\n",
    "def get_data_lumped(basin, basin_idx):\n",
    "    filepath = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    hc_data = pd.read_csv(filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start = pd.to_datetime(f\"{str(cali_start_list[basin_idx])}-01-01\")\n",
    "    cali_end   = pd.to_datetime(f\"{str(cali_end_list[basin_idx])}-12-31\")\n",
    "    vali_start = pd.to_datetime(f\"{str(vali_start_list[basin_idx])}-01-01\")\n",
    "    vali_end   = pd.to_datetime(f\"{str(vali_end_list[basin_idx])}-12-31\")\n",
    "\n",
    "    cali_data = hc_data.loc[cali_start : cali_end]\n",
    "    vali_data = hc_data.loc[vali_start : vali_end]\n",
    "\n",
    "    x_cali = cali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].to_numpy()\n",
    "    y_cali = cali_data['RUN'].to_numpy()\n",
    "    x_vali = vali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].to_numpy()\n",
    "    y_vali = vali_data['RUN'].to_numpy()\n",
    "    return x_cali, y_cali, x_vali, y_vali"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf540b9",
   "metadata": {},
   "source": [
    "# 获取流域属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52d22b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "Basin_Properties = pd.read_csv(\"../../Data/Properties/Basin_Properties.txt\", sep = '\\t', header=0, index_col='stat_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c641ed3",
   "metadata": {},
   "source": [
    "# 获取率定参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bd8ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_mYWBM   = pd.read_csv(\"../../Data/Params/03_mYWBM_Best_Params_CF.txt\", sep = '\\t', header=0, index_col='stat_num')\n",
    "params_abcd    = pd.read_csv(\"../../Data/Params/03_abcd_Best_Params_CF.txt\", sep = '\\t', header=0, index_col='stat_num')\n",
    "params_DWBM    = pd.read_csv(\"../../Data/Params/03_DWBM_Best_Params_CF.txt\", sep = '\\t', header=0, index_col='stat_num')\n",
    "params_GmYWBM  = pd.read_csv(\"../../Data/Params/03_GmYWBM_Best_Params_CF.txt\", sep = '\\t', header=0, index_col='stat_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b25c85",
   "metadata": {},
   "source": [
    "# 参数移植方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caae18d",
   "metadata": {},
   "source": [
    "## 地理临近法（空间距离相似）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1ab9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_by_SP_AM(basin_properties, params, N, lon, lat):\n",
    "    \"\"\"\n",
    "    使用空间临近法（地理临近法）算术平均为目标流域获取参数。\n",
    "    \n",
    "    参数：\n",
    "    -----------\n",
    "    basin_properties : np.ndarray\n",
    "        所有流域属性的数组，形状为 (n_basins, 2)，第0列为经度，第1列为纬度。\n",
    "    params : np.ndarray\n",
    "        所有流域参数的数组，形状为 (n_basins, n_params)。\n",
    "    N : int\n",
    "        用于参数移植的供体流域数量\n",
    "    lon : float\n",
    "        目标流域中心点的经度\n",
    "    lat : float\n",
    "        目标流域中心点的纬度\n",
    "    \n",
    "    返回：\n",
    "    --------\n",
    "    np.ndarray\n",
    "        目标流域的参数（N个最近流域参数的平均值）。\n",
    "    \"\"\"\n",
    "    # 提取经纬度\n",
    "    longitudes = basin_properties[:, 0]\n",
    "    latitudes = basin_properties[:, 1]\n",
    "\n",
    "    # 计算欧氏距离\n",
    "    distances = np.sqrt((longitudes - lon) ** 2 + (latitudes - lat) ** 2)\n",
    "    \n",
    "    # 找到距离最近的 N 个流域的索引\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    # 如果第一个距离非常小，认为是目标流域本身\n",
    "    if distances[sorted_indices[0]] <= 1e-5:\n",
    "        return params[sorted_indices[0]]\n",
    "    \n",
    "    # 获取最近的 N 个流域参数\n",
    "    nearest_params = params[sorted_indices[:N]]\n",
    "    \n",
    "    # 返回参数平均值\n",
    "    return nearest_params.mean(axis=0)\n",
    "\n",
    "def get_params_by_SP_IDW(basin_properties, params, N, lon, lat):\n",
    "    \"\"\"\n",
    "    使用空间临近法（地理临近法）反距离加权平均为目标流域获取参数。\n",
    "    \n",
    "    参数：\n",
    "    -----------\n",
    "    basin_properties : np.ndarray\n",
    "        所有流域属性的数组，形状为 (n_basins, 2)，第0列为经度，第1列为纬度。\n",
    "    params : np.ndarray\n",
    "        所有流域参数的数组，形状为 (n_basins, n_params)。\n",
    "    N : int\n",
    "        用于参数移植的供体流域数量\n",
    "    lon : float\n",
    "        目标流域中心点的经度\n",
    "    lat : float\n",
    "        目标流域中心点的纬度\n",
    "    \n",
    "    返回：\n",
    "    --------\n",
    "    np.ndarray\n",
    "        目标流域的参数（N个最近流域参数的平均值）。\n",
    "    \"\"\"\n",
    "    # 提取经纬度\n",
    "    longitudes = basin_properties[:, 0]\n",
    "    latitudes = basin_properties[:, 1]\n",
    "\n",
    "    # 计算欧氏距离\n",
    "    distances = np.sqrt((longitudes - lon) ** 2 + (latitudes - lat) ** 2)\n",
    "    \n",
    "    # 找到距离最近的 N 个流域的索引\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    # 如果第一个距离非常小，认为是目标流域本身\n",
    "    if distances[sorted_indices[0]] <= 1e-5:\n",
    "        return params[sorted_indices[0]]\n",
    "    \n",
    "    # 获取最近的 N 个流域参数和距离\n",
    "    nearest_params = params[sorted_indices[:N]]\n",
    "    nearest_distances = distances[sorted_indices[:N]]\n",
    "\n",
    "    # 计算反距离权重\n",
    "    weights = 1 / (nearest_distances + 1e-10)  # 防止除以零\n",
    "    weights /= weights.sum()\n",
    "\n",
    "    # 返回加权平均值\n",
    "    return (weights[:, np.newaxis] * nearest_params).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94dfbef",
   "metadata": {},
   "source": [
    "## 物理属性相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617cade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(target_properties, basin_properties, method='mahalanobis'):\n",
    "    \"\"\"\n",
    "    计算目标流域与其他流域之间的相似性。\n",
    "    可以使用马氏距离或余弦相似度。\n",
    "    \n",
    "    参数：\n",
    "    -----------\n",
    "    target_properties: 目标流域的属性 (1x19 numpy 数组或 pandas Series)\n",
    "    basin_properties: 所有流域的属性 (N x 19 numpy 数组或 pandas DataFrame)\n",
    "    method: 计算相似度的方法 ('mahalanobis' 或 'cosine')\n",
    "    \n",
    "    返回：\n",
    "    --------\n",
    "    list: 按相似性排序的流域索引\n",
    "    \"\"\"\n",
    "    if method == 'mahalanobis':\n",
    "        # 计算马氏距离\n",
    "        covariance_matrix = np.cov(basin_properties.T)\n",
    "        inverse_cov_matrix = np.linalg.inv(covariance_matrix)\n",
    "        similarities = []\n",
    "        \n",
    "        for basin in basin_properties:\n",
    "            dist = mahalanobis(np.squeeze(target_properties), basin, inverse_cov_matrix)\n",
    "            similarities.append(dist)\n",
    "    \n",
    "    elif method == 'cosine':\n",
    "        # 计算余弦相似度\n",
    "        similarities = pairwise_distances([target_properties], basin_properties, metric='cosine')[0]\n",
    "    \n",
    "    # 按相似度排序（升序）\n",
    "    sorted_indices = np.argsort(similarities)\n",
    "    return sorted_indices\n",
    "\n",
    "def get_params_by_PS(basin_properties, params, target_properties, N=5, method='mahalanobis'):\n",
    "    \"\"\"\n",
    "    使用物理相似性方法为目标流域获取参数。\n",
    "    \n",
    "    参数：\n",
    "    -----------\n",
    "    basin_properties: 所有流域的属性，包含19个属性 (numpy 数组或 pandas DataFrame)\n",
    "    params: 所有流域的参数 (numpy 数组或 pandas DataFrame)\n",
    "    target_properties: 目标流域的属性 (1x19 numpy 数组或 pandas Series)\n",
    "    N: 用于参数移植的相似流域数量\n",
    "    method: 计算相似度的方法 ('mahalanobis' 或 'cosine')\n",
    "    \n",
    "    返回：\n",
    "    --------\n",
    "    numpy.array: 目标流域的参数（N个最相似流域的参数平均值）\n",
    "    \"\"\"\n",
    "    # 标准化流域属性\n",
    "    scaler = StandardScaler()\n",
    "    basin_properties_scaled = scaler.fit_transform(basin_properties)\n",
    "    target_properties_scaled = scaler.transform(target_properties)  # 标准化目标流域属性\n",
    "    \n",
    "    # 使用PCA选择最重要的属性\n",
    "    pca = PCA(n_components=0.95)  # 保留95%的方差\n",
    "    basin_properties_pca = pca.fit_transform(basin_properties_scaled)\n",
    "    target_properties_pca = pca.transform(target_properties_scaled)\n",
    "    \n",
    "    # 计算目标流域与所有供体流域之间的相似性\n",
    "    similar_basins = calculate_similarity(target_properties_pca, basin_properties_pca, method)\n",
    "    \n",
    "    # 选择N个最相似的供体流域\n",
    "    selected_params = params[similar_basins[:N]]\n",
    "    \n",
    "    # 返回N个供体流域参数的平均值作为目标流域的参数\n",
    "    target_params = np.mean(selected_params, axis=0)\n",
    "    \n",
    "    return target_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10e51cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin_properties = np.random.rand(100, 19)  # 示例数据\n",
    "# params = np.random.rand(100, 5)  # 假设每个流域有5个参数\n",
    "# target_properties = np.random.rand(1, 19)  # 目标流域的19个属性\n",
    "\n",
    "# # 使用流域物理属性相似法获取目标流域的参数\n",
    "# target_params = get_params_by_physical_similarity(basin_properties, params, target_properties, N=5, method='mahalanobis')\n",
    "# print(\"Physical Similarity Predicted Parameters:\", target_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44a185f",
   "metadata": {},
   "source": [
    "## 回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e721d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(basin_properties_scaled, params):\n",
    "    \"\"\"\n",
    "    训练随机森林回归模型（多目标回归）\n",
    "    \n",
    "    参数：\n",
    "    - basin_properties_scaled: 所有流域的标准化后的属性，包含19个属性 (numpy 数组或 pandas DataFrame)\n",
    "    - params: 所有流域的参数 (numpy 数组或 pandas DataFrame)\n",
    "    \n",
    "    返回：\n",
    "    - trained_rf_model: 训练好的随机森林回归模型\n",
    "    \"\"\"\n",
    "    # 初始化并训练模型\n",
    "    rf_model = MultiOutputRegressor(RandomForestRegressor(n_estimators      = 100, \n",
    "                                                          max_depth         = 10,\n",
    "                                                          min_samples_split = 5,\n",
    "                                                          min_samples_leaf  = 2,\n",
    "                                                          random_state      = 42,\n",
    "                                                          n_jobs            = -1), n_jobs=-1)\n",
    "    rf_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return rf_model\n",
    "\n",
    "def train_svm(basin_properties_scaled, params):\n",
    "    \"\"\"\n",
    "    训练支持向量回归模型（多目标回归）\n",
    "    \n",
    "    参数：\n",
    "    - basin_properties_scaled: 所有流域的标准化后的属性，包含19个属性 (numpy 数组或 pandas DataFrame)\n",
    "    - params: 所有流域的参数 (numpy 数组或 pandas DataFrame)\n",
    "    \n",
    "    返回：\n",
    "    - trained_svm_model: 训练好的支持向量机回归模型\n",
    "    \"\"\"    \n",
    "    # 初始化并训练模型\n",
    "    svr_model = MultiOutputRegressor(SVR(kernel     = 'rbf',\n",
    "                                         C          = 100,\n",
    "                                         epsilon    = 0.01,\n",
    "                                         gamma      = 0.1), n_jobs=-1)\n",
    "    svr_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return svr_model\n",
    "\n",
    "def train_xgboost(basin_properties_scaled, params):\n",
    "    \"\"\"\n",
    "    训练XGBoost回归模型（多目标回归）\n",
    "    \n",
    "    参数：\n",
    "    - basin_properties_scaled: 所有流域的标准化后的属性，包含19个属性 (numpy 数组或 pandas DataFrame)\n",
    "    - params: 所有流域的参数 (numpy 数组或 pandas DataFrame)\n",
    "    \n",
    "    返回：\n",
    "    - trained_xgb_model: 训练好的XGBoost回归模型\n",
    "    \"\"\"\n",
    "    # 初始化并训练模型\n",
    "    xgb_model = MultiOutputRegressor(XGBRegressor(n_estimators      = 100,\n",
    "                                                  learning_rate     = 0.1,\n",
    "                                                  max_depth         = 6,\n",
    "                                                  min_child_weight  = 3,\n",
    "                                                  gamma             = 0.1,\n",
    "                                                  colsample_bytree  = 0.8,\n",
    "                                                  subsample         = 0.8,\n",
    "                                                  reg_alpha         = 0.1,\n",
    "                                                  random_state      = 42,\n",
    "                                                  n_jobs            = -1), n_jobs=-1)\n",
    "    xgb_model.fit(basin_properties_scaled, params)\n",
    "    \n",
    "    return xgb_model\n",
    "\n",
    "def get_params_by_regression(target_properties_scaled, trained_models):\n",
    "    \"\"\"\n",
    "    使用训练好的回归模型根据目标流域的属性预测多个参数。\n",
    "    \n",
    "    参数：\n",
    "    - target_properties_scaled: 目标流域的标准化后的属性 (1x19 numpy 数组或 pandas Series)\n",
    "    - model: 训练好的回归模型（可以是随机森林、支持向量机或XGBoost）\n",
    "    - scaler: 用于标准化的Scaler\n",
    "    \n",
    "    返回：\n",
    "    - predicted_params: 模型预测的多个参数\n",
    "    \"\"\"\n",
    "    # 使用模型进行预测\n",
    "    predicted_params = trained_models.predict(target_properties_scaled)\n",
    "    return np.squeeze(predicted_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2a82d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 示例数据\n",
    "# basin_properties = np.random.rand(100, 19)  # 100个流域的19个属性数据\n",
    "# params = np.random.rand(100, 5)  # 100个流域的参数数据，每个流域有5个参数\n",
    "# target_properties = np.random.rand(1, 19)  # 目标流域的19个属性数据\n",
    "\n",
    "# # 数据标准化\n",
    "# scaler = StandardScaler()\n",
    "# basin_properties_scaled = scaler.fit_transform(basin_properties)\n",
    "# target_properties_scaled = scaler.transform(target_properties)\n",
    "\n",
    "# rf_model  = train_random_forest(basin_properties_scaled, params)\n",
    "# svm_model = train_svm(basin_properties_scaled, params)\n",
    "# xgb_model = train_xgboost(basin_properties_scaled, params)\n",
    "\n",
    "# rf_pred   = get_params_by_regression(target_properties_scaled, rf_model)\n",
    "# svm_pred  = get_params_by_regression(target_properties_scaled, svm_model)\n",
    "# xgb_pred  = get_params_by_regression(target_properties_scaled, xgb_model)\n",
    "# print(\"Random Forest Predicted Parameters:\", rf_pred)\n",
    "# print(\"SVM Predicted Parameters:\", svm_pred)\n",
    "# print(\"XGBoost Predicted Parameters:\", xgb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efef80e",
   "metadata": {},
   "source": [
    "# 移植模型参数并计算效率系数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d24bd7d",
   "metadata": {},
   "source": [
    "## 定义结果数组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a035bb5",
   "metadata": {},
   "source": [
    "### 模型运行效率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122380c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mYWBM模型结果数组\n",
    "cali_kge_YM_list = np.full((len(basin_list), 6), np.nan)\n",
    "vali_kge_YM_list = np.full((len(basin_list), 6), np.nan)\n",
    "cali_re_YM_list  = np.full((len(basin_list), 6), np.nan)\n",
    "vali_re_YM_list  = np.full((len(basin_list), 6), np.nan)\n",
    "# abcd模型结果数组\n",
    "cali_kge_AM_list = np.full((len(basin_list), 6), np.nan)\n",
    "vali_kge_AM_list = np.full((len(basin_list), 6), np.nan)\n",
    "cali_re_AM_list  = np.full((len(basin_list), 6), np.nan)\n",
    "vali_re_AM_list  = np.full((len(basin_list), 6), np.nan)\n",
    "# DWBM模型结果数组\n",
    "cali_kge_DM_list = np.full((len(basin_list), 6), np.nan)\n",
    "vali_kge_DM_list = np.full((len(basin_list), 6), np.nan)\n",
    "cali_re_DM_list  = np.full((len(basin_list), 6), np.nan)\n",
    "vali_re_DM_list  = np.full((len(basin_list), 6), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da26d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_kge_YM_list = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Calibration_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_kge_YM_list = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Validation_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "cali_re_YM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Calibration_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_re_YM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Validation_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "\n",
    "cali_kge_AM_list = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Calibration_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_kge_AM_list = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Validation_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "cali_re_AM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Calibration_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_re_AM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Validation_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "\n",
    "cali_kge_DM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Calibration_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_kge_DM_list  = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Validation_KGE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "cali_re_DM_list   = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Calibration_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()\n",
    "vali_re_DM_list   = pd.read_csv(\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Validation_RE.txt\", sep = '\\t', header=0, index_col=0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620e9107",
   "metadata": {},
   "source": [
    "### 移植的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_YM_SP_AM     = np.full((len(basin_list), 5), np.nan)\n",
    "params_YM_SP_IDW    = np.full((len(basin_list), 5), np.nan)\n",
    "params_YM_PS        = np.full((len(basin_list), 5), np.nan)\n",
    "params_YM_rf        = np.full((len(basin_list), 5), np.nan)\n",
    "params_YM_svm       = np.full((len(basin_list), 5), np.nan)\n",
    "params_YM_xgb       = np.full((len(basin_list), 5), np.nan)\n",
    "\n",
    "params_AM_SP_AM     = np.full((len(basin_list), 5), np.nan)\n",
    "params_AM_SP_IDW    = np.full((len(basin_list), 5), np.nan)\n",
    "params_AM_PS        = np.full((len(basin_list), 5), np.nan)\n",
    "params_AM_rf        = np.full((len(basin_list), 5), np.nan)\n",
    "params_AM_svm       = np.full((len(basin_list), 5), np.nan)\n",
    "params_AM_xgb       = np.full((len(basin_list), 5), np.nan)\n",
    "\n",
    "params_DM_SP_AM     = np.full((len(basin_list), 5), np.nan)\n",
    "params_DM_SP_IDW    = np.full((len(basin_list), 5), np.nan)\n",
    "params_DM_PS        = np.full((len(basin_list), 5), np.nan)\n",
    "params_DM_rf        = np.full((len(basin_list), 5), np.nan)\n",
    "params_DM_svm       = np.full((len(basin_list), 5), np.nan)\n",
    "params_DM_xgb       = np.full((len(basin_list), 5), np.nan)\n",
    "\n",
    "params_GYM_SP_AM    = np.full((len(basin_list), 5), np.nan)\n",
    "params_GYM_SP_IDW   = np.full((len(basin_list), 5), np.nan)\n",
    "params_GYM_PS       = np.full((len(basin_list), 5), np.nan)\n",
    "params_GYM_rf       = np.full((len(basin_list), 5), np.nan)\n",
    "params_GYM_svm      = np.full((len(basin_list), 5), np.nan)\n",
    "params_GYM_xgb      = np.full((len(basin_list), 5), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333c490",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_YM_SP_AM     = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_SP_AM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_YM_SP_IDW    = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_SP_IDW_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_YM_PS        = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_PS_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_YM_rf        = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_RF_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_YM_svm       = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_SVM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_YM_xgb       = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_XGB_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "\n",
    "params_AM_SP_AM     = pd.read_csv(\"../../Results/Params_Transplant/abcd_SP_AM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_AM_SP_IDW    = pd.read_csv(\"../../Results/Params_Transplant/abcd_SP_IDW_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_AM_PS        = pd.read_csv(\"../../Results/Params_Transplant/abcd_PS_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_AM_rf        = pd.read_csv(\"../../Results/Params_Transplant/abcd_RF_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_AM_svm       = pd.read_csv(\"../../Results/Params_Transplant/abcd_SVM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_AM_xgb       = pd.read_csv(\"../../Results/Params_Transplant/abcd_XGB_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "\n",
    "params_DM_SP_AM     = pd.read_csv(\"../../Results/Params_Transplant/DWBM_SP_AM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_DM_SP_IDW    = pd.read_csv(\"../../Results/Params_Transplant/DWBM_SP_IDW_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_DM_PS        = pd.read_csv(\"../../Results/Params_Transplant/DWBM_PS_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_DM_rf        = pd.read_csv(\"../../Results/Params_Transplant/DWBM_RF_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_DM_svm       = pd.read_csv(\"../../Results/Params_Transplant/DWBM_SVM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_DM_xgb       = pd.read_csv(\"../../Results/Params_Transplant/DWBM_XGB_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "\n",
    "params_GYM_SP_AM     = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_SP_AM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_GYM_SP_IDW    = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_SP_IDW_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_GYM_PS        = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_PS_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_GYM_rf        = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_RF_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_GYM_svm       = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_SVM_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()\n",
    "params_GYM_xgb       = pd.read_csv(\"../../Results/Params_Transplant/GmYWBM_XGB_Params.txt\", sep='\\t', header=0, index_col=0).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac2e0d2",
   "metadata": {},
   "source": [
    "## 参数移植数据获取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "971b8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(basin, Basin_Properties, model_params):\n",
    "    # 获取该流域的经纬度\n",
    "    basin_lon = Basin_Properties.loc[basin]['Longitude']\n",
    "    basin_lat = Basin_Properties.loc[basin]['Latitude']\n",
    "    # 删除该流域的经纬度\n",
    "    # Basin_Properties = Basin_Properties.drop(columns=['Longitude', 'Latitude'])\n",
    "    # 获取率定的参数\n",
    "    cali_params = model_params.loc[basin].to_numpy()\n",
    "    # 获取流域属性\n",
    "    basin_properties = Basin_Properties.loc[basin].to_numpy().reshape(1, -1)\n",
    "    # 获取该流域剩余流域的属性\n",
    "    rest_properties = Basin_Properties.copy().drop(index=basin).to_numpy()\n",
    "    # 获取该流域剩余流域的参数\n",
    "    rest_params = model_params.copy().drop(index=basin).to_numpy()\n",
    "    return cali_params, basin_properties, rest_properties, rest_params, basin_lon, basin_lat\n",
    "def cal_metrics(cali_obs, vali_obs, cali_sim, vali_sim):\n",
    "    # 计算率定期和验证期的NSE和RE\n",
    "    cali_nse = kling_gupta_efficiency(cali_obs, cali_sim)\n",
    "    vali_nse = kling_gupta_efficiency(vali_obs, vali_sim)\n",
    "    cali_re  = relative_error(cali_obs, cali_sim) * 100\n",
    "    vali_re  = relative_error(vali_obs, vali_sim) * 100\n",
    "    return cali_nse, vali_nse, cali_re, vali_re\n",
    "def clean_params(params, all_params, lower_bound, upper_bound):\n",
    "    r, c = params.shape\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if params[i, j] < lower_bound[j] or params[i, j] > upper_bound[j]:\n",
    "                params[i, j] = np.nanmean(all_params[:, j])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa35cef",
   "metadata": {},
   "source": [
    "## 参数移植"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f566d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for basin_idx in range(len(basin_list)):\n",
    "def process_basin(basin_idx):\n",
    "    st = time.time()\n",
    "    basin = str(basin_list[basin_idx])\n",
    "    print(f\"Processing basin {basin} ({basin_idx + 1}/{len(basin_list)})...\")\n",
    "    \n",
    "    ## mYWBM\n",
    "    cali_params, basin_properties, rest_properties, rest_params, basin_lon, basin_lat = get_params(\n",
    "        basin, Basin_Properties[['Longitude', 'Latitude', 'Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']], params_mYWBM)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # source_properties_scaled = scaler.fit_transform(rest_properties[:, 2:])\n",
    "    # target_properties_scaled = scaler.transform(basin_properties[:, 2:])\n",
    "\n",
    "    # rf_model  = train_random_forest(source_properties_scaled, rest_params)\n",
    "    # svm_model = train_svm(source_properties_scaled, rest_params)\n",
    "    # xgb_model = train_xgboost(source_properties_scaled, rest_params)\n",
    "\n",
    "    pred_params_SP_AM   = get_params_by_SP_AM(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_SP_IDW  = get_params_by_SP_IDW(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_PS      = get_params_by_PS(rest_properties, rest_params, basin_properties, N=5, method='mahalanobis')\n",
    "    # pred_params_rf      = clean_params(get_params_by_regression(target_properties_scaled, rf_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "    # pred_params_svr     = clean_params(get_params_by_regression(target_properties_scaled, svm_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "    # pred_params_xgb     = clean_params(get_params_by_regression(target_properties_scaled, xgb_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "\n",
    "    params_YM_SP_AM[basin_idx]      = pred_params_SP_AM\n",
    "    params_YM_SP_IDW[basin_idx]     = pred_params_SP_IDW\n",
    "    params_YM_PS[basin_idx]         = pred_params_PS\n",
    "    # params_YM_rf[basin_idx]         = np.squeeze(pred_params_rf)\n",
    "    # params_YM_svm[basin_idx]        = np.squeeze(pred_params_svr)\n",
    "    # params_YM_xgb[basin_idx]        = np.squeeze(pred_params_xgb)\n",
    "\n",
    "    ## abcd\n",
    "    cali_params, basin_properties, rest_properties, rest_params, basin_lon, basin_lat = get_params(\n",
    "        basin, Basin_Properties[['Longitude', 'Latitude', 'Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']], params_abcd)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # source_properties_scaled = scaler.fit_transform(rest_properties[:, 2:])\n",
    "    # target_properties_scaled = scaler.transform(basin_properties[:, 2:])\n",
    "\n",
    "    # rf_model  = train_random_forest(source_properties_scaled, rest_params)\n",
    "    # svm_model = train_svm(source_properties_scaled, rest_params)\n",
    "    # xgb_model = train_xgboost(source_properties_scaled, rest_params)\n",
    "\n",
    "    pred_params_SP_AM   = get_params_by_SP_AM(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_SP_IDW  = get_params_by_SP_IDW(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_PS      = get_params_by_PS(rest_properties, rest_params, basin_properties, N=5, method='mahalanobis')\n",
    "    # pred_params_rf      = clean_params(get_params_by_regression(target_properties_scaled, rf_model).reshape(1, -1), rest_params, [0, 100, 0, 0, 0], [1, 2000, 1, 1, 1])\n",
    "    # pred_params_svr     = clean_params(get_params_by_regression(target_properties_scaled, svm_model).reshape(1, -1), rest_params, [0, 100, 0, 0, 0], [1, 2000, 1, 1, 1])\n",
    "    # pred_params_xgb     = clean_params(get_params_by_regression(target_properties_scaled, xgb_model).reshape(1, -1), rest_params, [0, 100, 0, 0, 0], [1, 2000, 1, 1, 1])\n",
    "\n",
    "    params_AM_SP_AM[basin_idx]      = pred_params_SP_AM\n",
    "    params_AM_SP_IDW[basin_idx]     = pred_params_SP_IDW\n",
    "    params_AM_PS[basin_idx]         = pred_params_PS\n",
    "    # params_AM_rf[basin_idx]         = np.squeeze(pred_params_rf)\n",
    "    # params_AM_svm[basin_idx]        = np.squeeze(pred_params_svr)\n",
    "    # params_AM_xgb[basin_idx]        = np.squeeze(pred_params_xgb)\n",
    "\n",
    "    ## DWBM模型\n",
    "    cali_params, basin_properties, rest_properties, rest_params, basin_lon, basin_lat = get_params(\n",
    "        basin, Basin_Properties[['Longitude', 'Latitude', 'Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']], params_DWBM)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # source_properties_scaled = scaler.fit_transform(rest_properties[:, 2:])\n",
    "    # target_properties_scaled = scaler.transform(basin_properties[:, 2:])\n",
    "\n",
    "    # rf_model  = train_random_forest(source_properties_scaled, rest_params)\n",
    "    # svm_model = train_svm(source_properties_scaled, rest_params)\n",
    "    # xgb_model = train_xgboost(source_properties_scaled, rest_params)\n",
    "\n",
    "    pred_params_SP_AM   = get_params_by_SP_AM(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_SP_IDW  = get_params_by_SP_IDW(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_PS      = get_params_by_PS(rest_properties, rest_params, basin_properties, N=5, method='mahalanobis')\n",
    "    # pred_params_rf      = clean_params(get_params_by_regression(target_properties_scaled, rf_model).reshape(1, -1), rest_params, [0, 0, 100, 0, 0], [1, 1, 2000, 1, 1])\n",
    "    # pred_params_svr     = clean_params(get_params_by_regression(target_properties_scaled, svm_model).reshape(1, -1), rest_params, [0, 0, 100, 0, 0], [1, 1, 2000, 1, 1])\n",
    "    # pred_params_xgb     = clean_params(get_params_by_regression(target_properties_scaled, xgb_model).reshape(1, -1), rest_params, [0, 0, 100, 0, 0], [1, 1, 2000, 1, 1])\n",
    "\n",
    "    params_DM_SP_AM[basin_idx]  = pred_params_SP_AM\n",
    "    params_DM_SP_IDW[basin_idx] = pred_params_SP_IDW\n",
    "    params_DM_PS[basin_idx]     = pred_params_PS\n",
    "    # params_DM_rf[basin_idx]     = np.squeeze(pred_params_rf)\n",
    "    # params_DM_svm[basin_idx]    = np.squeeze(pred_params_svr)\n",
    "    # params_DM_xgb[basin_idx]    = np.squeeze(pred_params_xgb)\n",
    "\n",
    "    ## GmYWBM模型\n",
    "    cali_params, basin_properties, rest_properties, rest_params, basin_lon, basin_lat = get_params(\n",
    "        basin, Basin_Properties[['Longitude', 'Latitude', 'Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'AE', 'NDVI', 'TI']], params_GmYWBM)\n",
    "\n",
    "    # scaler = StandardScaler()\n",
    "    # source_properties_scaled = scaler.fit_transform(rest_properties[:, 2:])\n",
    "    # target_properties_scaled = scaler.transform(basin_properties[:, 2:])\n",
    "\n",
    "    # rf_model  = train_random_forest(source_properties_scaled, rest_params)\n",
    "    # svm_model = train_svm(source_properties_scaled, rest_params)\n",
    "    # xgb_model = train_xgboost(source_properties_scaled, rest_params)\n",
    "\n",
    "    pred_params_SP_AM   = get_params_by_SP_AM(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_SP_IDW  = get_params_by_SP_IDW(rest_properties, rest_params, 8, basin_lon, basin_lat)\n",
    "    pred_params_PS      = get_params_by_PS(rest_properties, rest_params, basin_properties, N=5, method='mahalanobis')\n",
    "    # pred_params_rf      = clean_params(get_params_by_regression(target_properties_scaled, rf_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "    # pred_params_svr     = clean_params(get_params_by_regression(target_properties_scaled, svm_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "    # pred_params_xgb     = clean_params(get_params_by_regression(target_properties_scaled, xgb_model).reshape(1, -1), rest_params, [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 2000, 1])\n",
    "\n",
    "    params_GYM_SP_AM[basin_idx]     = pred_params_SP_AM\n",
    "    params_GYM_SP_IDW[basin_idx]    = pred_params_SP_IDW\n",
    "    params_GYM_PS[basin_idx]        = pred_params_PS\n",
    "    # params_GYM_rf[basin_idx]        = np.squeeze(pred_params_rf)\n",
    "    # params_GYM_svm[basin_idx]       = np.squeeze(pred_params_svr)\n",
    "    # params_GYM_xgb[basin_idx]       = np.squeeze(pred_params_xgb)\n",
    "\n",
    "#     et = time.time()\n",
    "#     print(f\"No. {basin_idx+1} 流域 {basin} 参数获取完成，耗时 {et - st:.2f} 秒\")\n",
    "\n",
    "# # 设置线程池大小（可以按 CPU 核数或手动指定）\n",
    "# max_workers = 10\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#     futures = [executor.submit(process_basin, i) for i in range(len(basin_list))]\n",
    "#     for future in as_completed(futures):\n",
    "#         future.result()\n",
    "\n",
    "for basin_idx in range(len(basin_list)):\n",
    "    process_basin(basin_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ebced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_YM_spatial_proximity_df    = pd.DataFrame(params_YM_spatial_proximity, index=params_mYWBM.index, columns=params_mYWBM.columns)\n",
    "# params_YM_physical_similarity_df  = pd.DataFrame(params_YM_physical_similarity, index=params_mYWBM.index, columns=params_mYWBM.columns)\n",
    "# params_YM_rf_df                   = pd.DataFrame(params_YM_rf, index=params_mYWBM.index, columns=params_mYWBM.columns)\n",
    "# params_YM_svm_df                  = pd.DataFrame(params_YM_svm, index=params_mYWBM.index, columns=params_mYWBM.columns)\n",
    "# params_YM_xgb_df                  = pd.DataFrame(params_YM_xgb, index=params_mYWBM.index, columns=params_mYWBM.columns)\n",
    "\n",
    "# params_AM_spatial_proximity_df    = pd.DataFrame(params_AM_spatial_proximity, index=params_abcd.index, columns=params_abcd.columns)\n",
    "# params_AM_physical_similarity_df  = pd.DataFrame(params_AM_physical_similarity, index=params_abcd.index, columns=params_abcd.columns)\n",
    "# params_AM_rf_df                   = pd.DataFrame(params_AM_rf, index=params_abcd.index, columns=params_abcd.columns)\n",
    "# params_AM_svm_df                  = pd.DataFrame(params_AM_svm, index=params_abcd.index, columns=params_abcd.columns)\n",
    "# params_AM_xgb_df                  = pd.DataFrame(params_AM_xgb, index=params_abcd.index, columns=params_abcd.columns)\n",
    "\n",
    "# params_DM_spatial_proximity_df    = pd.DataFrame(params_DM_spatial_proximity, index=params_DWBM.index, columns=params_DWBM.columns)\n",
    "# params_DM_physical_similarity_df  = pd.DataFrame(params_DM_physical_similarity, index=params_DWBM.index, columns=params_DWBM.columns)\n",
    "# params_DM_rf_df                   = pd.DataFrame(params_DM_rf, index=params_DWBM.index, columns=params_DWBM.columns)\n",
    "# params_DM_svm_df                  = pd.DataFrame(params_DM_svm, index=params_DWBM.index, columns=params_DWBM.columns)\n",
    "# params_DM_xgb_df                  = pd.DataFrame(params_DM_xgb, index=params_DWBM.index, columns=params_DWBM.columns)\n",
    "\n",
    "# params_YM_spatial_proximity_df.to_csv(\"../../Results/Params_Transplant/mYWBM_Spatial_Proximity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_YM_physical_similarity_df.to_csv(\"../../Results/Params_Transplant/mYWBM_Physical_Similarity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_YM_rf_df.to_csv(\"../../Results/Params_Transplant/mYWBM_RF_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_YM_svm_df.to_csv(\"../../Results/Params_Transplant/mYWBM_SVM_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_YM_xgb_df.to_csv(\"../../Results/Params_Transplant/mYWBM_XGB_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "\n",
    "# params_AM_spatial_proximity_df.to_csv(\"../../Results/Params_Transplant/abcd_Spatial_Proximity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_AM_physical_similarity_df.to_csv(\"../../Results/Params_Transplant/abcd_Physical_Similarity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_AM_rf_df.to_csv(\"../../Results/Params_Transplant/abcd_RF_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_AM_svm_df.to_csv(\"../../Results/Params_Transplant/abcd_SVM_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_AM_xgb_df.to_csv(\"../../Results/Params_Transplant/abcd_XGB_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "\n",
    "# params_DM_spatial_proximity_df.to_csv(\"../../Results/Params_Transplant/DWBM_Spatial_Proximity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_DM_physical_similarity_df.to_csv(\"../../Results/Params_Transplant/DWBM_Physical_Similarity_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_DM_rf_df.to_csv(\"../../Results/Params_Transplant/DWBM_RF_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_DM_svm_df.to_csv(\"../../Results/Params_Transplant/DWBM_SVM_Params.txt\", sep = '\\t', float_format='%.2f')\n",
    "# params_DM_xgb_df.to_csv(\"../../Results/Params_Transplant/DWBM_XGB_Params.txt\", sep = '\\t', float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb6409",
   "metadata": {},
   "source": [
    "## 读取参数移植结果并运行模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b18c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_YM_spatial_proximity_df      = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_Spatial_Proximity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_YM_physical_similarity_df    = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_Physical_Similarity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_YM_rf_df                     = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_RF_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_YM_svm_df                    = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_SVM_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_YM_xgb_df                    = pd.read_csv(\"../../Results/Params_Transplant/mYWBM_XGB_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "\n",
    "params_AM_spatial_proximity_df      = pd.read_csv(\"../../Results/Params_Transplant/abcd_Spatial_Proximity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_AM_physical_similarity_df    = pd.read_csv(\"../../Results/Params_Transplant/abcd_Physical_Similarity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_AM_rf_df                     = pd.read_csv(\"../../Results/Params_Transplant/abcd_RF_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_AM_svm_df                    = pd.read_csv(\"../../Results/Params_Transplant/abcd_SVM_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_AM_xgb_df                    = pd.read_csv(\"../../Results/Params_Transplant/abcd_XGB_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "\n",
    "params_DM_spatial_proximity_df      = pd.read_csv(\"../../Results/Params_Transplant/DWBM_Spatial_Proximity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_DM_physical_similarity_df    = pd.read_csv(\"../../Results/Params_Transplant/DWBM_Physical_Similarity_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_DM_rf_df                     = pd.read_csv(\"../../Results/Params_Transplant/DWBM_RF_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_DM_svm_df                    = pd.read_csv(\"../../Results/Params_Transplant/DWBM_SVM_Params.txt\", sep = '\\t', header=0, index_col=0)\n",
    "params_DM_xgb_df                    = pd.read_csv(\"../../Results/Params_Transplant/DWBM_XGB_Params.txt\", sep = '\\t', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bc144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models(fn_hm, basin_idx, x_cali, y_cali, x_vali, y_vali, cali_params_df, params_spatial_proximity_df, params_physical_similarity_df, params_rf_df, params_svm_df, params_xgb_df, cali_kge_list, vali_kge_list, cali_re_list, vali_re_list):\n",
    "    basin = str(basin_list[basin_idx])\n",
    "    # 获取参数\n",
    "    cali_params                     = cali_params_df.loc[basin].to_numpy() + 1e-6\n",
    "    pred_params_spatial_proximity   = params_spatial_proximity_df.loc[basin].to_numpy() + 1e-6\n",
    "    pred_params_physical_similarity = params_physical_similarity_df.loc[basin].to_numpy() + 1e-6\n",
    "    pred_params_rf                  = params_rf_df.loc[basin].to_numpy() + 1e-6\n",
    "    pred_params_svr                 = params_svm_df.loc[basin].to_numpy() + 1e-6\n",
    "    pred_params_xgb                 = params_xgb_df.loc[basin].to_numpy() + 1e-6\n",
    "\n",
    "    # 利用率定参数运行模型\n",
    "    y_sim_cali_caliparams = fn_hm(x_cali, cali_params)\n",
    "    y_sim_vali_caliparams = fn_hm(x_vali, cali_params)\n",
    "    # 利用空间临近法参数运行模型\n",
    "    y_sim_cali_spatial_proximity = fn_hm(x_cali, pred_params_spatial_proximity)\n",
    "    y_sim_vali_spatial_proximity = fn_hm(x_vali, pred_params_spatial_proximity)\n",
    "    # 利用物理相似性法参数运行模型\n",
    "    y_sim_cali_physical_similarity = fn_hm(x_cali, pred_params_physical_similarity)\n",
    "    y_sim_vali_physical_similarity = fn_hm(x_vali, pred_params_physical_similarity)\n",
    "    # 利用随机森林回归模型参数运行模型\n",
    "    y_sim_cali_rf = fn_hm(x_cali, pred_params_rf)\n",
    "    y_sim_vali_rf = fn_hm(x_vali, pred_params_rf)\n",
    "    # 利用支持向量机回归模型参数运行模型\n",
    "    y_sim_cali_svr = fn_hm(x_cali, pred_params_svr)\n",
    "    y_sim_vali_svr = fn_hm(x_vali, pred_params_svr)\n",
    "    # 利用XGBoost回归模型参数运行模型\n",
    "    y_sim_cali_xgb = fn_hm(x_cali, pred_params_xgb)\n",
    "    y_sim_vali_xgb = fn_hm(x_vali, pred_params_xgb)\n",
    "\n",
    "    # 计算NSE和RE\n",
    "    cali_kge_list[basin_idx, 0], vali_kge_list[basin_idx, 0], cali_re_list[basin_idx, 0], vali_re_list[basin_idx, 0] = cal_metrics(y_cali, y_vali, y_sim_cali_caliparams, y_sim_vali_caliparams)\n",
    "    cali_kge_list[basin_idx, 1], vali_kge_list[basin_idx, 1], cali_re_list[basin_idx, 1], vali_re_list[basin_idx, 1] = cal_metrics(y_cali, y_vali, y_sim_cali_spatial_proximity, y_sim_vali_spatial_proximity)\n",
    "    cali_kge_list[basin_idx, 2], vali_kge_list[basin_idx, 2], cali_re_list[basin_idx, 2], vali_re_list[basin_idx, 2] = cal_metrics(y_cali, y_vali, y_sim_cali_physical_similarity, y_sim_vali_physical_similarity)\n",
    "    cali_kge_list[basin_idx, 3], vali_kge_list[basin_idx, 3], cali_re_list[basin_idx, 3], vali_re_list[basin_idx, 3] = cal_metrics(y_cali, y_vali, y_sim_cali_rf, y_sim_vali_rf)\n",
    "    cali_kge_list[basin_idx, 4], vali_kge_list[basin_idx, 4], cali_re_list[basin_idx, 4], vali_re_list[basin_idx, 4] = cal_metrics(y_cali, y_vali, y_sim_cali_svr, y_sim_vali_svr)\n",
    "    cali_kge_list[basin_idx, 5], vali_kge_list[basin_idx, 5], cali_re_list[basin_idx, 5], vali_re_list[basin_idx, 5] = cal_metrics(y_cali, y_vali, y_sim_cali_xgb, y_sim_vali_xgb)\n",
    "    return cali_kge_list, vali_kge_list, cali_re_list, vali_re_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda5f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for basin_idx in range(len(basin_list)):\n",
    "    st = time.time()\n",
    "    basin = str(basin_list[basin_idx])\n",
    "    ## 集总式模型\n",
    "    fn_hm = mYWBMnlS\n",
    "    # 获取数据\n",
    "    x_cali, y_cali, x_vali, y_vali = get_data_lumped(basin, basin_idx)\n",
    "    cali_kge_YM_list, vali_kge_YM_list, cali_re_YM_list, vali_re_YM_list = run_models(fn_hm, basin_idx, x_cali, y_cali, x_vali, y_vali, \n",
    "                                                                                      params_mYWBM, params_YM_spatial_proximity_df, params_YM_physical_similarity_df, params_YM_rf_df, params_YM_svm_df, params_YM_xgb_df, \n",
    "                                                                                      cali_kge_YM_list, vali_kge_YM_list, cali_re_YM_list, vali_re_YM_list)\n",
    "\n",
    "    ## 分布式模型\n",
    "    fn_hm = abcdnlS\n",
    "    # 获取数据\n",
    "    x_cali, y_cali, x_vali, y_vali = get_data_lumped(basin, basin_idx)\n",
    "    cali_kge_AM_list, vali_kge_AM_list, cali_re_AM_list, vali_re_AM_list = run_models(fn_hm, basin_idx, x_cali, y_cali, x_vali, y_vali,\n",
    "                                                                                         params_abcd, params_AM_spatial_proximity_df, params_AM_physical_similarity_df, params_AM_rf_df, params_AM_svm_df, params_AM_xgb_df, \n",
    "                                                                                         cali_kge_AM_list, vali_kge_AM_list, cali_re_AM_list, vali_re_AM_list)\n",
    "    \n",
    "    ## RCCCWBM模型\n",
    "    fn_hm = DWBMnlS\n",
    "    # 获取数据\n",
    "    x_cali, y_cali, x_vali, y_vali = get_data_lumped(basin, basin_idx)\n",
    "    cali_kge_DM_list, vali_kge_DM_list, cali_re_DM_list, vali_re_DM_list = run_models(fn_hm, basin_idx, x_cali, y_cali, x_vali, y_vali,\n",
    "                                                                                         params_DWBM, params_DM_spatial_proximity_df, params_DM_physical_similarity_df, params_DM_rf_df, params_DM_svm_df, params_DM_xgb_df,\n",
    "                                                                                         cali_kge_DM_list, vali_kge_DM_list, cali_re_DM_list, vali_re_DM_list)\n",
    "    et = time.time()\n",
    "    print(f\"Processing No. {basin_idx+1}. basin {basin} finished, time: {et-st:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d7a69",
   "metadata": {},
   "source": [
    "# 保存数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0cb05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_kge_YM_df = pd.DataFrame(cali_kge_YM_list, index=params_mYWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_kge_YM_df = pd.DataFrame(vali_kge_YM_list, index=params_mYWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "cali_re_YM_df  = pd.DataFrame(cali_re_YM_list, index=params_mYWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_re_YM_df  = pd.DataFrame(vali_re_YM_list, index=params_mYWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "# cali_kge_YM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Calibration_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_kge_YM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Validation_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# cali_re_YM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Calibration_RE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_re_YM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_mYWBM_Validation_RE.txt\", sep='\\t', float_format='%.2f')\n",
    "\n",
    "cali_kge_AM_df = pd.DataFrame(cali_kge_AM_list, index=params_abcd.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_kge_AM_df = pd.DataFrame(vali_kge_AM_list, index=params_abcd.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "cali_re_AM_df  = pd.DataFrame(cali_re_AM_list, index=params_abcd.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_re_AM_df  = pd.DataFrame(vali_re_AM_list, index=params_abcd.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "# cali_kge_AM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Calibration_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_kge_AM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Validation_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# cali_re_AM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Calibration_RE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_re_AM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_abcd_Validation_RE.txt\", sep='\\t', float_format='%.2f')\n",
    "\n",
    "cali_kge_DM_df = pd.DataFrame(cali_kge_DM_list, index=params_DWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_kge_DM_df = pd.DataFrame(vali_kge_DM_list, index=params_DWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "cali_re_DM_df  = pd.DataFrame(cali_re_DM_list, index=params_DWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "vali_re_DM_df  = pd.DataFrame(vali_re_DM_list, index=params_DWBM.index, columns=['Calibrated', 'Spatial Proximity', 'Physical Similarity', 'Random Forest', 'SVM', 'XGBoost'])\n",
    "# cali_kge_DM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Calibration_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_kge_DM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Validation_KGE.txt\", sep='\\t', float_format='%.2f')\n",
    "# cali_re_DM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Calibration_RE.txt\", sep='\\t', float_format='%.2f')\n",
    "# vali_re_DM_df.to_csv(f\"../../Results/Metrics_Basin_Params_Transplant/1_DWBM_Validation_RE.txt\", sep='\\t', float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1d8dc",
   "metadata": {},
   "source": [
    "# 画图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69982758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_plot(basin_list, cali_df, vali_df):\n",
    "    df_plot = pd.DataFrame({\n",
    "        'Value': np.concatenate([\n",
    "            cali_df['Calibrated'].values,            vali_df['Calibrated'].values,\n",
    "            cali_df['Spatial Proximity'].values,     vali_df['Spatial Proximity'].values,\n",
    "            cali_df['Physical Similarity'].values,   vali_df['Physical Similarity'].values,\n",
    "            cali_df['Random Forest'].values,         vali_df['Random Forest'].values,\n",
    "            cali_df['SVM'].values,                   vali_df['SVM'].values,\n",
    "            cali_df['XGBoost'].values,               vali_df['XGBoost'].values\n",
    "        ]), \n",
    "        'Period': (['Cali'] * len(basin_list) + ['Vali'] * len(basin_list)) * 6,\n",
    "        'Method': ['Calibrated'] * len(basin_list) * 2 + ['Spatial Proximity'] * len(basin_list) * 2 +\n",
    "                    ['Physical Similarity'] * len(basin_list) * 2 + ['Random Forest'] * len(basin_list) * 2 +\n",
    "                    ['SVM'] * len(basin_list) * 2 + ['XGBoost'] * len(basin_list) * 2\n",
    "    })\n",
    "    return df_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kge_YM_df_plot  = get_df_plot(basin_list, cali_kge_YM_df, vali_kge_YM_df)\n",
    "re_YM_df_plot   = get_df_plot(basin_list, cali_re_YM_df, vali_re_YM_df)\n",
    "kge_AM_df_plot  = get_df_plot(basin_list, cali_kge_AM_df, vali_kge_AM_df)\n",
    "re_AM_df_plot   = get_df_plot(basin_list, cali_re_AM_df, vali_re_AM_df)\n",
    "kge_DM_df_plot  = get_df_plot(basin_list, cali_kge_DM_df, vali_kge_DM_df)\n",
    "re_DM_df_plot   = get_df_plot(basin_list, cali_re_DM_df, vali_re_DM_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c41ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxplot(ax, data, x, y, hue, title, ylabel, ylim):\n",
    "    sns.boxplot(ax=ax, data=data, x=x, y=y, hue=hue, palette='Set2', dodge=True, width=0.6, showfliers=False)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    ax.legend(title='', loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(16, 12))\n",
    "\n",
    "ax1_1 = axs[0, 0]\n",
    "ax1_2 = axs[0, 1]\n",
    "ax2_1 = axs[1, 0]\n",
    "ax2_2 = axs[1, 1]\n",
    "ax3_1 = axs[2, 0]\n",
    "ax3_2 = axs[2, 1]\n",
    "\n",
    "draw_boxplot(ax1_1, kge_YM_df_plot, 'Method', 'Value', 'Period', 'Kling-Gupta Efficiency for mYWBM', 'KGE', (-0.5, 1.0))\n",
    "draw_boxplot(ax1_2, re_YM_df_plot, 'Method', 'Value', 'Period', 'Relative Error for mYWBM', 'RE', (-40, 40))\n",
    "draw_boxplot(ax2_1, kge_DM_df_plot, 'Method', 'Value', 'Period', 'Kling-Gupta Efficiency for DWBM', 'KGE', (-0.5, 1.0))\n",
    "draw_boxplot(ax2_2, re_DM_df_plot, 'Method', 'Value', 'Period', 'Relative Error for DWBM', 'RE', (-40, 40))\n",
    "draw_boxplot(ax3_1, kge_AM_df_plot, 'Method', 'Value', 'Period', 'Kling-Gupta Efficiency for abcd', 'KGE', (-0.5, 1.0))\n",
    "draw_boxplot(ax3_2, re_AM_df_plot, 'Method', 'Value', 'Period', 'Relative Error for abcd', 'RE', (-40, 40))\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(\"../../Images/Compare_Parameter_Estimation_Methods.jpg\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc35a9b3",
   "metadata": {},
   "source": [
    "# 将参数移植到格点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf32f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义nc读取函数\n",
    "def read_nc(filepath, var_name, flip=True):\n",
    "    ds = xr.open_dataset(filepath)\n",
    "    if flip:\n",
    "        data = np.fliplr(np.rot90(ds[var_name].values, k=3))  # 逆时针旋转90度\n",
    "    else:\n",
    "        data = ds[var_name].values\n",
    "    ds.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66595a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_mask    = read_nc(\"../../Data/Grids_Prop/mask.nc\", \"mask\")\n",
    "grids_climate = read_nc(\"../../Data/Grids_Prop/Climate.nc\", \"Climate\")\n",
    "grids_clay    = read_nc(\"../../Data/Grids_Prop/clay.nc\", \"clay\")\n",
    "grids_silt    = read_nc(\"../../Data/Grids_Prop/silt.nc\", \"silt\")\n",
    "grids_sand    = read_nc(\"../../Data/Grids_Prop/sand.nc\", \"sand\")\n",
    "grids_slope   = read_nc(\"../../Data/Grids_Prop/Slope.nc\", \"Slope\")\n",
    "grids_bfi     = read_nc(\"../../Data/Grids_Prop/BFI.nc\", \"BFI\")\n",
    "grids_pre     = read_nc(\"../../Data/Grids_Prop/pre.nc\", \"pre\")\n",
    "grids_tmp     = read_nc(\"../../Data/Grids_Prop/tem.nc\", \"tem\")\n",
    "grids_pet     = read_nc(\"../../Data/Grids_Prop/pet.nc\", \"pet\") * 30.4\n",
    "grids_tmax    = read_nc(\"../../Data/Grids_Prop/tmx.nc\", \"tmx\")\n",
    "grids_tmin    = read_nc(\"../../Data/Grids_Prop/tmn.nc\", \"tmn\")\n",
    "grids_ndvi    = read_nc(\"../../Data/Grids_Prop/NDVI.nc\", \"NDVI\")\n",
    "grids_ti      = read_nc(\"../../Data/Grids_Prop/TI.nc\", \"TI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeaa0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = np.arange(0, 360*720)\n",
    "hang_list = (num_list // 720).astype(int)\n",
    "lie_list  = (num_list % 720).astype(int)\n",
    "mask_list = grids_mask.flatten()\n",
    "\n",
    "climate_list = grids_climate.flatten()\n",
    "clay_list    = grids_clay.flatten()\n",
    "silt_list    = grids_silt.flatten()\n",
    "sand_list    = grids_sand.flatten()\n",
    "slope_list   = grids_slope.flatten()\n",
    "bfi_list     = grids_bfi.flatten()\n",
    "pre_list     = grids_pre.flatten()\n",
    "tmp_list     = grids_tmp.flatten()\n",
    "pet_list     = grids_pet.flatten()\n",
    "tmax_list    = grids_tmax.flatten()\n",
    "tmin_list    = grids_tmin.flatten()\n",
    "ndvi_list    = grids_ndvi.flatten()\n",
    "ti_list      = grids_ti.flatten()\n",
    "\n",
    "grids_prop = pd.DataFrame({\n",
    "    'Climate': climate_list, 'Clay': clay_list, 'Silt': silt_list, 'Sand': sand_list, 'Slope': slope_list, 'BFI' : bfi_list,\n",
    "    'PRE'    : pre_list,     'TMP' : tmp_list,  'PET' : pet_list,  'TMAX': tmax_list, 'TMIN' : tmin_list,  'NDVI': ndvi_list,\n",
    "    'TI'     : ti_list,      'NUM' : num_list,  'HANG': hang_list, 'LIE' : lie_list,  'MASK' : mask_list\n",
    "})\n",
    "grids_prop = grids_prop[grids_prop['MASK'] == 1].reset_index(drop=True)\n",
    "# 舍弃grids_prop中含有NaN值的行\n",
    "grids_prop = grids_prop.dropna().reset_index(drop=True)\n",
    "grids_prop.set_index('NUM', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a984c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids_prop.to_csv(\"../../Data/Grids_Prop/Grids_Properties.txt\", sep='\\t', float_format='%.4f', index=True)\n",
    "grids_prop_np = grids_prop[['Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'NDVI', 'TI']].to_numpy()\n",
    "\n",
    "basin_props_np  = Basin_Properties[['Climate', 'Clay', 'Silt', 'Sand', 'Slope', 'BFI', 'PRE', 'TMP', 'PET', 'TMAX', 'TMIN', 'NDVI', 'TI']].to_numpy()\n",
    "params_mYWBM_np = params_mYWBM.to_numpy()\n",
    "params_abcd_np  = params_abcd.to_numpy()\n",
    "params_DWBM_np  = params_DWBM.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a545e7b0",
   "metadata": {},
   "source": [
    "### 利用物理相似性移植和RF移植参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b44de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids_params_YM_PS  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "# grids_params_YM_rf  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "# grids_params_AM_PS  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "# grids_params_AM_rf  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "# grids_params_DM_PS  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "# grids_params_DM_rf  = np.full((grids_prop.shape[0], 5), np.nan)\n",
    "\n",
    "# # 物理相似性移植\n",
    "# for i in trange(grids_prop.shape[0]):\n",
    "#     grids_params_YM_PS[i, :] = get_params_by_PS(basin_props_np, params_mYWBM_np, grids_prop_np[i].reshape(1, -1))\n",
    "#     grids_params_AM_PS[i, :] = get_params_by_PS(basin_props_np, params_abcd_np, grids_prop_np[i].reshape(1, -1))\n",
    "#     grids_params_DM_PS[i, :] = get_params_by_PS(basin_props_np, params_DWBM_np, grids_prop_np[i].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61cb493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_params_YM_PS = pd.read_csv(\"../../Results/Grids_Params_Transplant/YM_PS.txt\", sep='\\t', header=0, index_col=0)[['Ks', 'Kg', 'alpha', 'smax', 'Ksn']].values\n",
    "grids_params_AM_PS = pd.read_csv(\"../../Results/Grids_Params_Transplant/AM_PS.txt\", sep='\\t', header=0, index_col=0)[['a', 'b', 'c', 'd', 'Ksn']].values\n",
    "grids_params_DM_PS = pd.read_csv(\"../../Results/Grids_Params_Transplant/DM_PS.txt\", sep='\\t', header=0, index_col=0)[['alpha1', 'alpha2', 'smax', 'd', 'Ksn']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 随机森林回归移植\n",
    "# scaler = StandardScaler()\n",
    "# source_properties_scaled = scaler.fit_transform(basin_props_np)\n",
    "# target_properties_scaled = scaler.transform(grids_prop_np)\n",
    "\n",
    "# rf_model_YM = train_random_forest(source_properties_scaled, params_mYWBM)\n",
    "# rf_model_AM = train_random_forest(source_properties_scaled, params_abcd)\n",
    "# rf_model_DM = train_random_forest(source_properties_scaled, params_DWBM)\n",
    "\n",
    "# pred_params_YM_RF  = clean_params(get_params_by_regression(target_properties_scaled, rf_model_YM), params_mYWBM.to_numpy(), [0, 0, 0.05, 100, 0], [2, 0.65, 0.95, 1000, 1])\n",
    "# pred_params_AM_RF  = clean_params(get_params_by_regression(target_properties_scaled, rf_model_AM), params_abcd.to_numpy(), [0, 100, 0, 0, 0], [1, 2000, 1, 1, 1])\n",
    "# pred_params_DM_RF  = clean_params(get_params_by_regression(target_properties_scaled, rf_model_DM), params_DWBM.to_numpy(), [0, 0, 100, 0, 0], [1, 1, 2000, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d51e0e",
   "metadata": {},
   "source": [
    "### 把两组参数根据grids_loc的顺序放回去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_grids_PS_YM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# kg_grids_PS_YM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# alpha_grids_PS_YM = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# smax_grids_PS_YM  = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_PS_YM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "\n",
    "# ks_grids_RF_YM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# kg_grids_RF_YM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# alpha_grids_RF_YM  = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# smax_grids_RF_YM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_RF_YM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "\n",
    "# a_grids_PS_AM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# b_grids_PS_AM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# c_grids_PS_AM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# d_grids_PS_AM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_PS_AM  = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "\n",
    "# a_grids_RF_AM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# b_grids_RF_AM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# c_grids_RF_AM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# d_grids_RF_AM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_RF_AM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "\n",
    "# alpha1_grids_PS_DM = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# alpha2_grids_PS_DM = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# smax_grids_PS_DM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# d_grids_PS_DM      = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_PS_DM    = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "\n",
    "# alpha1_grids_RF_DM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# alpha2_grids_RF_DM   = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# smax_grids_RF_DM     = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# d_grids_RF_DM        = np.full_like(grids_mask, np.nan, dtype=float)\n",
    "# ksn_grids_RF_DM      = np.full_like(grids_mask, np.nan, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ks_grids_PS_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_YM_PS[:, 0]\n",
    "# kg_grids_PS_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_YM_PS[:, 1]\n",
    "# alpha_grids_PS_YM[grids_prop['HANG'].values, grids_prop['LIE'].values] = grids_params_YM_PS[:, 2]\n",
    "# smax_grids_PS_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]  = grids_params_YM_PS[:, 3]\n",
    "# ksn_grids_PS_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]   = grids_params_YM_PS[:, 4]\n",
    "\n",
    "# ks_grids_RF_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_YM_RF[:, 0]\n",
    "# kg_grids_RF_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_YM_RF[:, 1]\n",
    "# alpha_grids_RF_YM[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_params_YM_RF[:, 2]\n",
    "# smax_grids_RF_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]  = pred_params_YM_RF[:, 3]\n",
    "# ksn_grids_RF_YM[grids_prop['HANG'].values, grids_prop['LIE'].values]   = pred_params_YM_RF[:, 4]\n",
    "\n",
    "# a_grids_PS_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_AM_PS[:, 0]\n",
    "# b_grids_PS_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_AM_PS[:, 1]\n",
    "# c_grids_PS_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_AM_PS[:, 2]\n",
    "# d_grids_PS_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_AM_PS[:, 3]\n",
    "# ksn_grids_PS_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]  = grids_params_AM_PS[:, 4]\n",
    "\n",
    "# a_grids_RF_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_AM_RF[:, 0]\n",
    "# b_grids_RF_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_AM_RF[:, 1]\n",
    "# c_grids_RF_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_AM_RF[:, 2]\n",
    "# d_grids_RF_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_AM_RF[:, 3]\n",
    "# ksn_grids_RF_AM[grids_prop['HANG'].values, grids_prop['LIE'].values]  = pred_params_AM_RF[:, 4]\n",
    "\n",
    "# alpha1_grids_PS_DM[grids_prop['HANG'].values, grids_prop['LIE'].values] = grids_params_DM_PS[:, 0]\n",
    "# alpha2_grids_PS_DM[grids_prop['HANG'].values, grids_prop['LIE'].values] = grids_params_DM_PS[:, 1]\n",
    "# smax_grids_PS_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]   = grids_params_DM_PS[:, 2]\n",
    "# d_grids_PS_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]      = grids_params_DM_PS[:, 3]\n",
    "# ksn_grids_PS_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = grids_params_DM_PS[:, 4]\n",
    "\n",
    "# alpha1_grids_RF_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_DM_RF[:, 0]\n",
    "# alpha2_grids_RF_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]    = pred_params_DM_RF[:, 1]\n",
    "# smax_grids_RF_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]      = pred_params_DM_RF[:, 2]\n",
    "# d_grids_RF_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]         = pred_params_DM_RF[:, 3]\n",
    "# ksn_grids_RF_DM[grids_prop['HANG'].values, grids_prop['LIE'].values]       = pred_params_DM_RF[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636be09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(5, 6, figsize=(25, 13))\n",
    "# plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "# param_names = ['Ks', 'Kg', 'Alpha', 'Smax', 'Ksn']\n",
    "# method_names = ['mY_Phy', 'mY_RF', 'AM_Phy', 'AM_RF', 'DM_Phy', 'DM_RF']\n",
    "\n",
    "# # Data for plotting\n",
    "# data_to_plot = [\n",
    "#     [ks_grids_physical_similarity_YM,    ks_grids_rf_YM,    a_grids_physical_similarity_AM,   a_grids_rf_AM,   alpha1_grids_physical_similarity_DM, alpha1_grids_rf_DM],\n",
    "#     [kg_grids_physical_similarity_YM,    kg_grids_rf_YM,    b_grids_physical_similarity_AM,   b_grids_rf_AM,   alpha2_grids_physical_similarity_DM, alpha2_grids_rf_DM],\n",
    "#     [alpha_grids_physical_similarity_YM, alpha_grids_rf_YM, c_grids_physical_similarity_AM,   c_grids_rf_AM,   smax_grids_physical_similarity_DM,   smax_grids_rf_DM],\n",
    "#     [smax_grids_physical_similarity_YM,  smax_grids_rf_YM,  d_grids_physical_similarity_AM,   d_grids_rf_AM,   d_grids_physical_similarity_DM,      d_grids_rf_DM],\n",
    "#     [ksn_grids_physical_similarity_YM,   ksn_grids_rf_YM,   ksn_grids_physical_similarity_AM, ksn_grids_rf_AM, ksn_grids_physical_similarity_DM,    ksn_grids_rf_DM]\n",
    "# ]\n",
    "\n",
    "# for i in range(5):  # Rows for parameters\n",
    "#     for j in range(6):  # Columns for methods\n",
    "#         ax = axs[i, j]\n",
    "#         im = ax.imshow(data_to_plot[i][j], cmap='viridis', aspect='auto')\n",
    "#         ax.set_title(f'{param_names[i]} - {method_names[j]}')\n",
    "#         ax.set_xlabel('Longitude Index')\n",
    "#         ax.set_ylabel('Latitude Index')\n",
    "#         fig.colorbar(im, ax=ax, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "\n",
    "# fig.suptitle('Spatial Distribution of Transplanted Parameters', fontsize=16, fontweight='bold')\n",
    "# plt.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust layout to make space for suptitle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e9c4b9",
   "metadata": {},
   "source": [
    "### 写入nc文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bd1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_nc(filepath, lon, lat, ks, kg, alpha, smax, ksn):\n",
    "#     # 创建一个新的NetCDF文件\n",
    "#     ds = xr.Dataset(\n",
    "#         {\n",
    "#             'ks': (['lat', 'lon'], ks),\n",
    "#             'kg': (['lat', 'lon'], kg),\n",
    "#             'alpha': (['lat', 'lon'], alpha),\n",
    "#             'smax': (['lat', 'lon'], smax),\n",
    "#             'ksn': (['lat', 'lon'], ksn)\n",
    "#         },\n",
    "#         coords={\n",
    "#             'lon': (['lon'], lon),\n",
    "#             'lat': (['lat'], lat)\n",
    "#         }\n",
    "#     )\n",
    "#     ds.to_netcdf(filepath, mode='w')\n",
    "#     ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aeccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids_lon = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").longitude.values\n",
    "# grids_lat = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").latitude.values\n",
    "\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", grids_lon, grids_lat,\n",
    "#          ks_grids_PS_YM, kg_grids_PS_YM, alpha_grids_PS_YM,\n",
    "#          smax_grids_PS_YM, ksn_grids_PS_YM)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/YM_RF.nc\", grids_lon, grids_lat,\n",
    "#          ks_grids_RF_YM, kg_grids_RF_YM, alpha_grids_RF_YM,\n",
    "#          smax_grids_RF_YM, ksn_grids_RF_YM)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", grids_lon, grids_lat,\n",
    "#             a_grids_PS_AM, b_grids_PS_AM, c_grids_PS_AM,\n",
    "#             d_grids_PS_AM, ksn_grids_PS_AM)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/AM_RF.nc\", grids_lon, grids_lat,\n",
    "#             a_grids_RF_AM, b_grids_RF_AM, c_grids_RF_AM,\n",
    "#             d_grids_RF_AM, ksn_grids_RF_AM)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", grids_lon, grids_lat,\n",
    "#          alpha1_grids_PS_DM, alpha2_grids_PS_DM, smax_grids_PS_DM,\n",
    "#          d_grids_PS_DM, ksn_grids_PS_DM)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/DM_RF.nc\", grids_lon, grids_lat,\n",
    "#          alpha1_grids_RF_DM, alpha2_grids_RF_DM, smax_grids_RF_DM,\n",
    "#          d_grids_RF_DM, ksn_grids_RF_DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f3a5f",
   "metadata": {},
   "source": [
    "### 读取格点参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25bc8d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_grids_PS_YM    = read_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", \"ks\", False)\n",
    "kg_grids_PS_YM    = read_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", \"kg\", False)\n",
    "alpha_grids_PS_YM = read_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", \"alpha\", False)\n",
    "smax_grids_PS_YM  = read_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", \"smax\", False)\n",
    "ksn_grids_PS_YM   = read_nc(\"../../Results/Grids_Params_Transplant/YM_PS.nc\", \"ksn\", False)\n",
    "\n",
    "ks_grids_rf_YM    = read_nc(\"../../Results/Grids_Params_Transplant/YM_rf.nc\", \"ks\", False)\n",
    "kg_grids_rf_YM    = read_nc(\"../../Results/Grids_Params_Transplant/YM_rf.nc\", \"kg\", False)\n",
    "alpha_grids_rf_YM = read_nc(\"../../Results/Grids_Params_Transplant/YM_rf.nc\", \"alpha\", False)\n",
    "smax_grids_rf_YM  = read_nc(\"../../Results/Grids_Params_Transplant/YM_rf.nc\", \"smax\", False)\n",
    "ksn_grids_rf_YM   = read_nc(\"../../Results/Grids_Params_Transplant/YM_rf.nc\", \"ksn\", False)\n",
    "\n",
    "a_grids_PS_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", \"ks\", False)\n",
    "b_grids_PS_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", \"kg\", False)\n",
    "c_grids_PS_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", \"alpha\", False)\n",
    "d_grids_PS_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", \"smax\", False)\n",
    "ksn_grids_PS_AM = read_nc(\"../../Results/Grids_Params_Transplant/AM_PS.nc\", \"ksn\", False)\n",
    "\n",
    "a_grids_rf_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_rf.nc\", \"ks\", False)\n",
    "b_grids_rf_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_rf.nc\", \"kg\", False)\n",
    "c_grids_rf_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_rf.nc\", \"alpha\", False)\n",
    "d_grids_rf_AM   = read_nc(\"../../Results/Grids_Params_Transplant/AM_rf.nc\", \"smax\", False)\n",
    "ksn_grids_rf_AM = read_nc(\"../../Results/Grids_Params_Transplant/AM_rf.nc\", \"ksn\", False)\n",
    "\n",
    "alpha1_grids_PS_DM = read_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", \"ks\", False)\n",
    "alpha2_grids_PS_DM = read_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", \"kg\", False)\n",
    "smax_grids_PS_DM   = read_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", \"alpha\", False)\n",
    "d_grids_PS_DM      = read_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", \"smax\", False)\n",
    "ksn_grids_PS_DM    = read_nc(\"../../Results/Grids_Params_Transplant/DM_PS.nc\", \"ksn\", False)\n",
    "\n",
    "alpha1_grids_rf_DM  = read_nc(\"../../Results/Grids_Params_Transplant/DM_rf.nc\", \"ks\", False)\n",
    "alpha2_grids_rf_DM  = read_nc(\"../../Results/Grids_Params_Transplant/DM_rf.nc\", \"kg\", False)\n",
    "smax_grids_rf_DM    = read_nc(\"../../Results/Grids_Params_Transplant/DM_rf.nc\", \"alpha\", False)\n",
    "d_grids_rf_DM       = read_nc(\"../../Results/Grids_Params_Transplant/DM_rf.nc\", \"smax\", False)\n",
    "ksn_grids_rf_DM     = read_nc(\"../../Results/Grids_Params_Transplant/DM_rf.nc\", \"ksn\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3588a7b",
   "metadata": {},
   "source": [
    "# 预估格点的最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4b48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_results = pd.read_csv(\"../../Results/Best_Model_Transplant/Best_Model_Calibration.txt\", sep=\"\\t\", index_col='stat_num')[['BM_3']]\n",
    "\n",
    "# models = {\n",
    "#     \"RandomForest\": RandomForestClassifier(n_estimators=200, random_state=42),\n",
    "#     \"SVM\": Pipeline([(\"scaler\", StandardScaler()), \n",
    "#                      (\"clf\", SVC(kernel=\"rbf\", probability=True, random_state=42))]),\n",
    "#     \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.01, random_state=42),\n",
    "#     \"KNN\": Pipeline([(\"scaler\", StandardScaler()), \n",
    "#                      (\"clf\", KNeighborsClassifier(n_neighbors=15))])\n",
    "# }\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# source_properties_scaled = scaler.fit_transform(basin_props_np)\n",
    "# y_train = sim_results['BM_3'].values - 1\n",
    "\n",
    "# target_properties_scaled = scaler.transform(grids_prop_np)\n",
    "\n",
    "# trained_rf_model  = models['RandomForest'].fit(source_properties_scaled, y_train)\n",
    "# trained_svm_model = models['SVM'].fit(source_properties_scaled, y_train)\n",
    "# trained_xgb_model = models['XGBoost'].fit(source_properties_scaled, y_train)\n",
    "# trained_knn_model = models['KNN'].fit(source_properties_scaled, y_train)\n",
    "\n",
    "# pred_grids_best_model_rf  = trained_rf_model.predict(target_properties_scaled)\n",
    "# pred_grids_best_model_svm = trained_svm_model.predict(target_properties_scaled)\n",
    "# pred_grids_best_model_xgb = trained_xgb_model.predict(target_properties_scaled)\n",
    "# pred_grids_best_model_knn = trained_knn_model.predict(target_properties_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grids_best_model_rf  = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "# grids_best_model_svm = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "# grids_best_model_xgb = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "# grids_best_model_knn = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "\n",
    "# grids_best_model_rf[grids_prop['HANG'].values, grids_prop['LIE'].values]  = pred_grids_best_model_rf\n",
    "# grids_best_model_svm[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_best_model_svm\n",
    "# grids_best_model_xgb[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_best_model_xgb\n",
    "# grids_best_model_knn[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_best_model_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def write_nc(filepath, lon, lat, best_model):\n",
    "#     # 创建一个新的NetCDF文件\n",
    "#     ds = xr.Dataset(\n",
    "#         {\n",
    "#             'best_model': (['lat', 'lon'], best_model),\n",
    "#         },\n",
    "#         coords={\n",
    "#             'lon': (['lon'], lon),\n",
    "#             'lat': (['lat'], lat)\n",
    "#         }\n",
    "#     )\n",
    "#     ds.to_netcdf(filepath, mode='w')\n",
    "#     ds.close()\n",
    "# grids_lon = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").longitude.values\n",
    "# grids_lat = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").latitude.values\n",
    "\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/Best_Model_rf.nc\", grids_lon, grids_lat, grids_best_model_rf)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/Best_Model_svm.nc\", grids_lon, grids_lat, grids_best_model_svm)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/Best_Model_xgb.nc\", grids_lon, grids_lat, grids_best_model_xgb)\n",
    "# write_nc(\"../../Results/Grids_Params_Transplant/Best_Model_knn.nc\", grids_lon, grids_lat, grids_best_model_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5352879",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_Model_rf = read_nc(\"../../Results/Grids_Params_Transplant/Best_Model_rf.nc\", \"best_model\", False)\n",
    "Best_Model_svm = read_nc(\"../../Results/Grids_Params_Transplant/Best_Model_svm.nc\", \"best_model\", False)\n",
    "Best_Model_xgb = read_nc(\"../../Results/Grids_Params_Transplant/Best_Model_xgb.nc\", \"best_model\", False)\n",
    "Best_Model_knn = read_nc(\"../../Results/Grids_Params_Transplant/Best_Model_knn.nc\", \"best_model\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a701fc",
   "metadata": {},
   "source": [
    "# 预估格点的模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0df677eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = pd.read_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_AIAC.txt\", sep=\"\\t\", index_col='stat_num')[['r_w_YM', 'r_w_AM', 'r_w_DM']]\n",
    "\n",
    "sim_results.loc[(sim_results[['r_w_YM', 'r_w_AM', 'r_w_DM']].sum(axis=1) == 0), 'r_w_YM'] = 1\n",
    "\n",
    "sim_results['new_w_YM'] = sim_results['r_w_YM'] / (sim_results['r_w_YM'] + sim_results['r_w_AM'] + sim_results['r_w_DM'])\n",
    "sim_results['new_w_AM'] = sim_results['r_w_AM'] / (sim_results['r_w_YM'] + sim_results['r_w_AM'] + sim_results['r_w_DM'])\n",
    "sim_results['new_w_DM'] = sim_results['r_w_DM'] / (sim_results['r_w_YM'] + sim_results['r_w_AM'] + sim_results['r_w_DM'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "source_properties_scaled = scaler.fit_transform(basin_props_np)\n",
    "y_train = sim_results[['new_w_YM', 'new_w_AM', 'new_w_DM']].values\n",
    "\n",
    "target_properties_scaled = scaler.transform(grids_prop_np)\n",
    "\n",
    "trained_rf_model  = train_random_forest(source_properties_scaled, y_train)\n",
    "trained_svr_model = train_svm(source_properties_scaled, y_train)\n",
    "trained_xgb_model = train_xgboost(source_properties_scaled, y_train)\n",
    "\n",
    "pred_grids_model_weight_rf  = get_params_by_regression(target_properties_scaled, trained_rf_model)\n",
    "pred_grids_model_weight_svr = get_params_by_regression(target_properties_scaled, trained_svr_model)\n",
    "pred_grids_model_weight_xgb = get_params_by_regression(target_properties_scaled, trained_xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32241a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_model_weight_YM_rf = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_AM_rf = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_DM_rf = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "\n",
    "grids_model_weight_YM_svr = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_AM_svr = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_DM_svr = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "\n",
    "grids_model_weight_YM_xgb = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_AM_xgb = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "grids_model_weight_DM_xgb = np.full_like(grids_mask, np.nan, dtype=np.float32)\n",
    "\n",
    "grids_model_weight_YM_rf[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_rf[:, 0]\n",
    "grids_model_weight_AM_rf[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_rf[:, 1]\n",
    "grids_model_weight_DM_rf[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_rf[:, 2]\n",
    "\n",
    "grids_model_weight_YM_svr[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_svr[:, 0]\n",
    "grids_model_weight_AM_svr[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_svr[:, 1]\n",
    "grids_model_weight_DM_svr[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_svr[:, 2]\n",
    "\n",
    "grids_model_weight_YM_xgb[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_xgb[:, 0]\n",
    "grids_model_weight_AM_xgb[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_xgb[:, 1]\n",
    "grids_model_weight_DM_xgb[grids_prop['HANG'].values, grids_prop['LIE'].values] = pred_grids_model_weight_xgb[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755a4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_nc(filepath, lon, lat, weight_YM, weight_AM, weight_DM):\n",
    "    # 创建一个新的NetCDF文件\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            'weight_YM': (['lat', 'lon'], weight_YM),\n",
    "            'weight_AM': (['lat', 'lon'], weight_AM),\n",
    "            'weight_DM': (['lat', 'lon'], weight_DM),\n",
    "        },\n",
    "        coords={\n",
    "            'lon': (['lon'], lon),\n",
    "            'lat': (['lat'], lat)\n",
    "        }\n",
    "    )\n",
    "    ds.to_netcdf(filepath, mode='w')\n",
    "    ds.close()\n",
    "\n",
    "grids_lon = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").longitude.values\n",
    "grids_lat = xr.open_dataset(\"../../Data/Grids_Prop/mask.nc\").latitude.values\n",
    "\n",
    "write_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_rf.nc\", grids_lon, grids_lat,\n",
    "         grids_model_weight_YM_rf, grids_model_weight_AM_rf, grids_model_weight_DM_rf)\n",
    "write_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_svr.nc\", grids_lon, grids_lat,\n",
    "         grids_model_weight_YM_svr, grids_model_weight_AM_svr, grids_model_weight_DM_svr)\n",
    "write_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_xgb.nc\", grids_lon, grids_lat,\n",
    "         grids_model_weight_YM_xgb, grids_model_weight_AM_xgb, grids_model_weight_DM_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d00283",
   "metadata": {},
   "source": [
    "# 气象数据驱动格点模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e72fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grid_params(filepath):\n",
    "    grids_param_dataset = Dataset(filepath, 'r')\n",
    "    grid_param_1 = grids_param_dataset.variables['ks'][:].data\n",
    "    grid_param_2 = grids_param_dataset.variables['kg'][:].data\n",
    "    grid_param_3 = grids_param_dataset.variables['alpha'][:].data\n",
    "    grid_param_4 = grids_param_dataset.variables['smax'][:].data\n",
    "    grid_param_5 = grids_param_dataset.variables['ksn'][:].data\n",
    "    grids_param_dataset.close()\n",
    "    params_PhS_3d = np.stack([grid_param_1, grid_param_2, grid_param_3, grid_param_4, grid_param_5], axis=-1)\n",
    "    return params_PhS_3d\n",
    "\n",
    "def read_forcing_data(filepath, element):\n",
    "    forcing_dataset = Dataset(filepath, 'r')\n",
    "    forcing_data = forcing_dataset[element][:].data.swapaxes(1, 2)\n",
    "    return forcing_data\n",
    "\n",
    "params_grids_YM_PhS = read_grid_params(\"../../Results/Grids_Params_Transplant/YM_PhS.nc\")\n",
    "params_grids_AM_PhS = read_grid_params(\"../../Results/Grids_Params_Transplant/AM_PhS.nc\")\n",
    "params_grids_DM_PhS = read_grid_params(\"../../Results/Grids_Params_Transplant/DM_PhS.nc\")\n",
    "\n",
    "dataset   = \"gswp3\"\n",
    "start_time = 1971\n",
    "end_time   = 2010\n",
    "data_time = f\"{start_time}_{end_time}\"\n",
    "time_series = pd.date_range(start=f\"{start_time}-01\", end=f\"{end_time}-12\", freq='MS')\n",
    "time_delta  = (time_series - pd.Timestamp('1900-01-01')).days.values\n",
    "\n",
    "pr_data  = np.load(f\"../../Data/forcing/pr_{dataset}_{data_time}.npy\").astype(np.float32)\n",
    "tas_data = np.load(f\"../../Data/forcing/tas_{dataset}_{data_time}.npy\").astype(np.float32)\n",
    "pet_data = np.load(f\"../../Data/forcing/pet_{dataset}_{data_time}.npy\").astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140c46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rsim_YM = np.full_like(pr_data, np.nan, dtype=np.float32)\n",
    "Rsim_AM = np.full_like(pr_data, np.nan, dtype=np.float32)\n",
    "Rsim_DM = np.full_like(pr_data, np.nan, dtype=np.float32)\n",
    "\n",
    "Esim_YM = np.full_like(pr_data, np.nan, dtype=np.float32)\n",
    "Esim_AM = np.full_like(pr_data, np.nan, dtype=np.float32)\n",
    "Esim_DM = np.full_like(pr_data, np.nan, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(grids_prop.shape[0]):\n",
    "    hang = grids_prop.iloc[i]['HANG'].astype(int)\n",
    "    lie  = grids_prop.iloc[i]['LIE'].astype(int)\n",
    "    pr   = pr_data[:, hang, lie] + 1e-5\n",
    "    tas  = tas_data[:, hang, lie] + 1e-5\n",
    "    pet  = pet_data[:, hang, lie] + 1e-5\n",
    "    params_YM = params_grids_YM_PhS[hang, lie]\n",
    "    params_AM = params_grids_AM_PhS[hang, lie]\n",
    "    params_DM = params_grids_DM_PhS[hang, lie]\n",
    "    grid_forcing = np.vstack([pr, tas, pet]).T\n",
    "    Rsim_YM[:, hang, lie], Esim_YM[:, hang, lie] = mYWBMnlS_RE(grid_forcing, params_YM)\n",
    "    Rsim_AM[:, hang, lie], Esim_AM[:, hang, lie] = abcdnlS_RE(grid_forcing, params_AM)\n",
    "    Rsim_DM[:, hang, lie], Esim_DM[:, hang, lie] = DWBMnlS_RE(grid_forcing, params_DM)\n",
    "\n",
    "Rsim_YM = Rsim_YM.astype(np.float16)\n",
    "Rsim_AM = Rsim_AM.astype(np.float16)\n",
    "Rsim_DM = Rsim_DM.astype(np.float16)\n",
    "Esim_YM = Esim_YM.astype(np.float16)\n",
    "Esim_AM = Esim_AM.astype(np.float16)\n",
    "Esim_DM = Esim_DM.astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8129546",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_YM_{dataset}.npy\", Rsim_YM)\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_AM_{dataset}.npy\", Rsim_AM)\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_DM_{dataset}.npy\", Rsim_DM)\n",
    "\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_YM_{dataset}.npy\", Esim_YM)\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_AM_{dataset}.npy\", Esim_AM)\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_DM_{dataset}.npy\", Esim_DM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d1b4b",
   "metadata": {},
   "source": [
    "# 格点模拟结果的加权平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"gswp3\"\n",
    "# 加载结果\n",
    "Rsim_YM = np.load(f\"../../Results/Grids_Simulation_Results/Rsim_YM_{dataset}.npy\")\n",
    "Rsim_AM = np.load(f\"../../Results/Grids_Simulation_Results/Rsim_AM_{dataset}.npy\")\n",
    "Rsim_DM = np.load(f\"../../Results/Grids_Simulation_Results/Rsim_DM_{dataset}.npy\")\n",
    "\n",
    "Esim_YM = np.load(f\"../../Results/Grids_Simulation_Results/Esim_YM_{dataset}.npy\")\n",
    "Esim_AM = np.load(f\"../../Results/Grids_Simulation_Results/Esim_AM_{dataset}.npy\")\n",
    "Esim_DM = np.load(f\"../../Results/Grids_Simulation_Results/Esim_DM_{dataset}.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ceb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算术平均\n",
    "Rsim_ArM = (Rsim_YM + Rsim_AM + Rsim_DM) / 3\n",
    "Esim_ArM = (Esim_YM + Esim_AM + Esim_DM) / 3\n",
    "\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_ArM_{dataset}.npy\", Rsim_ArM.astype(np.float16))\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_ArM_{dataset}.npy\", Esim_ArM.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加权平均\n",
    "grids_model_weight_YM_svr = read_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_svr.nc\", \"weight_YM\", False)\n",
    "grids_model_weight_AM_svr = read_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_svr.nc\", \"weight_AM\", False)\n",
    "grids_model_weight_DM_svr = read_nc(\"../../Results/Grids_Params_Transplant/Model_Weight_svr.nc\", \"weight_DM\", False)\n",
    "\n",
    "Rsim_WeM_svr = Rsim_YM * grids_model_weight_YM_svr + Rsim_AM * grids_model_weight_AM_svr + Rsim_DM * grids_model_weight_DM_svr\n",
    "Esim_WeM_svr = Esim_YM * grids_model_weight_YM_svr + Esim_AM * grids_model_weight_AM_svr + Esim_DM * grids_model_weight_DM_svr\n",
    "\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_WeM_svr_{dataset}.npy\", Rsim_WeM_svr.astype(np.float16))\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_WeM_svr_{dataset}.npy\", Esim_WeM_svr.astype(np.float16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaab8f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动识别最佳模型\n",
    "grids_best_model_svm = read_nc(\"../../Results/Grids_Params_Transplant/Best_Model_svm.nc\", \"best_model\", False)\n",
    "\n",
    "grids_model_weight_YM_svr = (grids_best_model_svm == 0).astype(np.float32)\n",
    "grids_model_weight_AM_svr = (grids_best_model_svm == 1).astype(np.float32)\n",
    "grids_model_weight_DM_svr = (grids_best_model_svm == 2).astype(np.float32)\n",
    "\n",
    "Rsim_BeM_svr = Rsim_YM * grids_model_weight_YM_svr + Rsim_AM * grids_model_weight_AM_svr + Rsim_DM * grids_model_weight_DM_svr\n",
    "Esim_BeM_svr = Esim_YM * grids_model_weight_YM_svr + Esim_AM * grids_model_weight_AM_svr + Esim_DM * grids_model_weight_DM_svr\n",
    "\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Rsim_BeM_svr_{dataset}.npy\", Rsim_BeM_svr.astype(np.float16))\n",
    "np.save(f\"../../Results/Grids_Simulation_Results/Esim_BeM_svr_{dataset}.npy\", Esim_BeM_svr.astype(np.float16))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
