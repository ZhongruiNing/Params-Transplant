{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb85f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from Water_Blance_Model import mYWBMnlS_RE, abcdnlS_RE, DWBMnlS_RE, GmYWBM_RE\n",
    "from Rewrite_Func import nash_sutcliffe_efficiency, relative_error, kling_gupta_efficiency\n",
    "from numba import float64, njit\n",
    "from numba.experimental import jitclass\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.ndimage import median_filter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import trange\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c2c45",
   "metadata": {},
   "source": [
    "## é€æµåŸŸç®— AIC/BIC & æ€§èƒ½æŒ‡æ ‡ â†’ åˆ¤å®šæ˜¾è‘—æ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd564804",
   "metadata": {},
   "source": [
    "ä¸‹é¢ç»™å‡º **Step 2ï¼šé€æµåŸŸç®— AIC/BIC ï¼‹ æ€§èƒ½æŒ‡æ ‡å¹¶åˆ¤æ–­æ˜¾è‘—æ€§** çš„ä¸€å¥— *å¯ç›´æ¥è½åœ°* çš„æµç¨‹å’Œç¤ºä¾‹ä»£ç æ¡†æ¶ã€‚ä½ åªéœ€æŠŠè‡ªå·±çš„è§‚æµ‹å’Œæ¨¡æ‹Ÿç»“æœå¡«è¿›å»å³å¯è¿è¡Œã€‚æ•´å¥—æµç¨‹åˆ†æˆ â¶â€“â» å…­æ­¥ï¼›å…¶ä¸­ â¹â€“â» æ˜¯å¯é€‰è¿›é˜¶ï¼Œç”¨æ¥ç»™å‡ºç»Ÿè®¡æ˜¾è‘—æ€§å’Œâ€œä¼˜èƒœæ¦‚ç‡â€åˆ¤å®šã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## â¶ å‡†å¤‡æ•°æ®\n",
    "\n",
    "| å˜é‡            | è¯´æ˜                  | å»ºè®®æ ¼å¼                              |\n",
    "| ------------- | ------------------- | --------------------------------- |\n",
    "| `Q_obs`       | è§‚æµ‹æ—¥ï¼ˆæˆ–æœˆï¼‰å¾„æµæ—¶é—´åºåˆ—       | `numpy.ndarray` æˆ– `pandas.Series` |\n",
    "| `Q_mod_A/B/C` | ä¸‰ä¸ªæ¨¡å‹å¯¹åŒä¸€æ—¶æ®µçš„æ¨¡æ‹Ÿ        | åŒä¸Š                                |\n",
    "| `n`           | æœ‰æ•ˆæ ·æœ¬é•¿åº¦ï¼ˆå»æ‰ç¼ºæµ‹åçš„ç‚¹æ•°ï¼‰    | `int`                             |\n",
    "| `k_A/B/C`     | å„æ¨¡å‹è‡ªç”±å‚æ•°ä¸ªæ•°ï¼ˆå«è¯¯å·®æ–¹å·® ÏƒÂ²ï¼‰ | `int`                             |\n",
    "\n",
    "> ğŸ’¡ **æ³¨æ„**ï¼šå¦‚æœä½ å¯¹æ®‹å·®åš Boxâ€“Cox å˜æ¢æˆ– log å˜æ¢ï¼Œè®°å¾—æŠŠ **Î»**ï¼ˆBoxâ€“Cox å‚æ•°ï¼‰ä¹Ÿç®—è¿› `k`ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## â· è®¡ç®—å¯¹æ•°ä¼¼ç„¶ `lnL`\n",
    "\n",
    "å¸¸ç”¨å‡è®¾ï¼š\n",
    "\n",
    "* ç»è¿‡å˜æ¢çš„æ®‹å·® \\~ N (Î¼, ÏƒÂ²)ï¼Œç‹¬ç«‹åŒåˆ†å¸ƒã€‚\n",
    "* ç»™å®š Ïƒï¼Œä»¥æ®‹å·®å¹³æ–¹å’Œ (SSR) ç›´æ¥æ±‚å¯¹æ•°ä¼¼ç„¶ï¼š\n",
    "\n",
    "$$\n",
    "\\ln L = -\\frac{n}{2}\\left[\\ln(2\\pi\\sigma^2)\\right]-\\frac{1}{2\\sigma^2}\\sum_{t=1}^{n} (e_t-Î¼)^2\n",
    "$$\n",
    "\n",
    "å…¶ä¸­\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n}\\sum_{t=1}^{n} (e_t)^2\n",
    "$$\n",
    "\n",
    "### Python å‡½æ•°ç¤ºä¾‹\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def loglik_gaussian(residuals: np.ndarray) -> float:\n",
    "    n = residuals.size\n",
    "    sigma2 = residuals.var(ddof=0)\n",
    "    return -0.5 * n * (np.log(2*np.pi*sigma2) + 1)\n",
    "\n",
    "def loglik_gaussian_with_mu(residuals):\n",
    "    n = residuals.size\n",
    "    mu_hat = residuals.mean()\n",
    "    sigma2_hat = ((residuals - mu_hat) ** 2).mean()\n",
    "    lnL = -0.5 * n * (np.log(2*np.pi*sigma2_hat) + 1)\n",
    "    return lnL, mu_hat, sigma2_hat\n",
    "```\n",
    "\n",
    "å½“ä½ è€ƒè™‘ Î¼ å’Œ ÏƒÂ² éƒ½ä¸ºæ¨¡å‹å‚æ•°æ—¶ï¼ŒåŠ¡å¿…æ›´æ–°å‚æ•°ä¸ªæ•°k:\n",
    "\n",
    "$$\n",
    "k = k_{æ¨¡å‹å‚æ•°}+2\n",
    "$$\n",
    "\n",
    "å…¶ä¸­â€œ2â€æ¥è‡ªÎ¼å’ŒÏƒÂ²\n",
    "\n",
    "---\n",
    "\n",
    "## â¸ è®¡ç®— AIC / BIC åŠ Î”AIC / Î”BIC\n",
    "\n",
    "```python\n",
    "def information_criteria(lnL: float, k: int, n: int):\n",
    "    AIC = 2*k - 2*lnL\n",
    "    BIC = k*np.log(n) - 2*lnL\n",
    "    return AIC, BIC\n",
    "```\n",
    "\n",
    "* **æ¯ä¸ªæµåŸŸ**ç®—ä¸‰ç»„ (A, B, C)ã€‚\n",
    "* æ‰¾åˆ°è¯¥æµåŸŸ AIC/BIC æœ€å°çš„æ¨¡å‹ï¼Œè®°ä¸º *best*ï¼›å…¶ä½™æ¨¡å‹çš„\n",
    "\n",
    "  $$\n",
    "  \\Delta\\text{AIC}_m = \\text{AIC}_m - \\text{AIC}_{best}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\Delta\\text{BIC}_m = \\text{BIC}_m - \\text{BIC}_{best}\n",
    "  $$\n",
    "\n",
    "åˆ¤å®šè§„åˆ™ï¼ˆå¸¸ç”¨é˜ˆå€¼ï¼‰ï¼š\n",
    "\n",
    "| Î”AIC/Î”BIC | 0â€“2    | 2â€“4 | 4â€“10 | > 10 |\n",
    "| --------- | ------ | --- | ---- | ---- |\n",
    "| è§£é‡Š        | è¯æ®å‡ ä¹ç›¸åŒ | ç•¥å¥½  | æ˜æ˜¾å¥½  | æå…¶æ˜¾è‘— |\n",
    "\n",
    "---\n",
    "\n",
    "## â¹ è®¡ç®—æ€§èƒ½æŒ‡æ ‡ï¼ˆNSEã€KGEâ€¦ï¼‰\n",
    "\n",
    "```python\n",
    "def nse(obs, sim):\n",
    "    return 1 - (((obs - sim) ** 2).sum() /\n",
    "                ((obs - obs.mean()) ** 2).sum())\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r   = np.corrcoef(obs, sim)[0,1]\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta  = sim.mean() / obs.mean()\n",
    "    return 1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2)\n",
    "```\n",
    "\n",
    "ä¿å­˜åˆ°åŒä¸€ä¸ª `DataFrame`ï¼Œåé¢å¯ç›´æ¥åšå·®ï¼š\n",
    "\n",
    "$$\n",
    "\\Delta\\text{NSE}_{C-B} = \\text{NSE}_C - \\text{NSE}_B\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## âº åˆ¤å®šå·®å¼‚æ˜¾è‘—æ€§ï¼ˆä¸¤æ¡æ€è·¯ï¼Œè‡³å°‘é€‰å…¶ä¸€ï¼‰\n",
    "\n",
    "### A. ä¿¡æ¯å‡†åˆ™é˜ˆå€¼æ³•ï¼ˆå¿«é€Ÿï¼‰\n",
    "\n",
    "* åœ¨æ¯ä¸ªæµåŸŸï¼šè‹¥ **Î”BIC<4**ï¼Œè§†ä¸ºâ€œå·®åˆ«ä¸è¶³â€ï¼›\n",
    "  è‹¥ **Î”BIC â‰¥ 4** ä¸” C æœ€ä½³ â†’ è®°ä½œ â€œC æ˜¾è‘—ä¼˜â€ï¼›\n",
    "  è‹¥ C ä¸æ˜¯æœ€ä½³ â†’ â€œC ä¸ä¼˜â€ã€‚\n",
    "* ä¼˜ç¼ºç‚¹ï¼šç®€å•ï¼Œä½†åªä¾èµ–ä¼¼ç„¶ï¼Œä¸çœ‹ NSE/KGEã€‚\n",
    "\n",
    "### B. Bootstrapped æ€§èƒ½å·®å¼‚ç½®ä¿¡åŒºé—´ï¼ˆæ›´ç¨³å¥ï¼‰\n",
    "\n",
    "1. **å¯¹é½æ—¥æœŸ**ï¼šä¿æŒ `obs` ä¸ `sim` åŒé•¿ã€‚\n",
    "2. **å—è‡ªåŠ©æ³• (block bootstrap)**ï¼š\n",
    "\n",
    "   ```python\n",
    "   import random\n",
    "   block = 30  # 30 å¤©å—\n",
    "   n_bs  = 1000\n",
    "   diff  = []\n",
    "   for _ in range(n_bs):\n",
    "       idx = []\n",
    "       while len(idx) < len(obs):\n",
    "           start = random.randint(0, len(obs)-block)\n",
    "           idx.extend(range(start, start+block))\n",
    "       idx = idx[:len(obs)]\n",
    "       diff.append(nse(obs[idx], simC[idx]) -\n",
    "                   nse(obs[idx], simB[idx]))\n",
    "   lo, hi = np.percentile(diff, [2.5, 97.5])\n",
    "   signif = (lo > 0) or (hi < 0)   # Trueâ†’æ˜¾è‘—\n",
    "   ```\n",
    "3. ç»Ÿè®¡ 2003 ä¸ªæµåŸŸé‡Œ `signif==True` ä¸” C ä¼˜çš„æ¯”ä¾‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## â» ï¼ˆå¯é€‰ï¼‰è½¬åŒ–ä¸º **åéªŒæ¨¡å‹æ¦‚ç‡ PMP** ä»¥ä¾¿åç»­ BMA\n",
    "\n",
    "æ¨¡å‹æƒé‡ï¼š\n",
    "\n",
    "$$\n",
    "w_m = \\exp\\!\\left(-\\frac{1}{2}\\,\\Delta\\text{BIC}_m\\right),\\qquad\n",
    "\\text{PMP}_m = \\frac{w_m}{\\sum_{j} w_j}\n",
    "$$\n",
    "\n",
    "ä¸€æ­¥ Pythonï¼š\n",
    "\n",
    "```python\n",
    "weights = np.exp(-0.5 * delta_BIC_array)\n",
    "PMP     = weights / weights.sum(axis=1, keepdims=True)\n",
    "```\n",
    "\n",
    "åˆ°æ­¤ï¼Œä¸€ä¸ªåŒ…å«å­—æ®µ\n",
    "\n",
    "\\| basin\\_id | best\\_model | Î”AIC\\_A/B/C | Î”BIC\\_A/B/C | NSE\\_A/B/C | KGE\\_A/B/C | signif\\_CvsB | PMP\\_A/B/C |\n",
    "\n",
    "çš„æ€»è¡¨ï¼ˆ`DataFrame` æˆ– `Parquet`ï¼‰å°±å‡†å¤‡å¥½äº†ï¼Œå¯ç”¨äºåç»­ **Step 3 äº¤å‰éªŒè¯ + BMA** ä»¥åŠå¸•ç´¯æ‰˜åˆ†æã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404f799",
   "metadata": {},
   "source": [
    "# å®šä¹‰æµåŸŸä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–æµåŸŸä¿¡æ¯\n",
    "basin_info      = pd.read_excel('../../Data/Basin_Selection/All_Selected_Basins.xlsx')\n",
    "basin_list      = basin_info['stat_num']\n",
    "cali_start_list = basin_info['cali_start']\n",
    "cali_end_list   = basin_info['cali_end']\n",
    "vali_start_list = basin_info['vali_start']\n",
    "vali_end_list   = basin_info['vali_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8290ef4",
   "metadata": {},
   "source": [
    "# å®šä¹‰æ•°æ®è¯»å–å‡½æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d488bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é›†æ€»å¼æ¨¡å‹æ•°æ®è¯»å–\n",
    "def get_data_lumped(basin, basin_idx):\n",
    "    filepath = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    hc_data = pd.read_csv(filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start = pd.to_datetime(f\"{str(cali_start_list[basin_idx])}-01-01\")\n",
    "    cali_end   = pd.to_datetime(f\"{str(cali_end_list[basin_idx])}-12-31\")\n",
    "    vali_start = pd.to_datetime(f\"{str(vali_start_list[basin_idx])}-01-01\")\n",
    "    vali_end   = pd.to_datetime(f\"{str(vali_end_list[basin_idx])}-12-31\")\n",
    "    esim_start = pd.Timestamp('1980-01-01')\n",
    "    esim_end   = pd.Timestamp('2022-12-31')\n",
    "\n",
    "    cali_data = hc_data.loc[cali_start : cali_end]\n",
    "    vali_data = hc_data.loc[vali_start : vali_end]\n",
    "    esim_data = hc_data.loc[esim_start : esim_end]\n",
    "\n",
    "    x_cali = cali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "    y_cali = cali_data['RUN'].values\n",
    "    x_vali = vali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "    y_vali = vali_data['RUN'].values\n",
    "    x_esim = esim_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "\n",
    "    ae_filepath = f\"../../../2025_03_Hydrological_Models/Data/AE/AE_{basin}.txt\"\n",
    "    ae_obs = pd.read_csv(ae_filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "\n",
    "    y_esim = ae_obs['AE'].values\n",
    "    return x_cali, y_cali, x_vali, y_vali, x_esim, y_esim\n",
    "\n",
    "STP = pd.read_excel(\"../../../2025_03_Hydrological_Models/Raw_Data/D_TEXTURE_USDA.xlsx\")\n",
    "STP = STP[['CODE', 's', 'fc', 'wp']].to_numpy()\n",
    "\n",
    "def read_georaster(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        temp_data = src.read(1)\n",
    "        new_data = temp_data.copy().astype(np.float64)\n",
    "        new_data[new_data < 0] = np.nan\n",
    "        # è·å–ç»çº¬åº¦èŒƒå›´\n",
    "        bounds = src.bounds\n",
    "        # è·å–åˆ†è¾¨ç‡\n",
    "        res = src.res\n",
    "        # ç”Ÿæˆç»çº¬åº¦åæ ‡\n",
    "        lon = np.round(np.arange(bounds.left + res[0] / 2, bounds.right, res[0]), 3)\n",
    "        lat = np.round(np.arange(bounds.top - res[1] / 2, bounds.bottom, -res[1]), 3)\n",
    "    return new_data, lon, lat, bounds, res[0]\n",
    "\n",
    "def read_nc(filepath, varname):\n",
    "    cf_info = Dataset(filepath)\n",
    "    cf_data = np.rot90(np.flip(cf_info.variables[varname][:].data, axis=1), k = -1, axes=(1 ,2))\n",
    "    cf_lon = cf_info.variables['lon'][:].data\n",
    "    cf_lat = cf_info.variables['lat'][:].data\n",
    "    cf_info.close()\n",
    "    return cf_data, cf_lon, cf_lat\n",
    "\n",
    "spec = [\n",
    "    ('PRE',      float64[:, :, :]),\n",
    "    ('TMP',      float64[:, :, :]),\n",
    "    ('PET',      float64[:, :, :]),\n",
    "    ('TI',       float64[:, :]),\n",
    "    ('ST',       float64[:, :]),\n",
    "    ('STP',      float64[:, :]),\n",
    "    ('mask',     float64[:, :]),\n",
    "    ('mask_res', float64),\n",
    "    ('mask_lon', float64[:]),\n",
    "    ('mask_lat', float64[:]),\n",
    "    ('TI_lon',   float64[:]),\n",
    "    ('TI_lat',   float64[:]),\n",
    "]\n",
    "@jitclass(spec)\n",
    "class inputData:\n",
    "    def __init__(self, PRE, TMP, PET, TI, ST, STP, mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat):\n",
    "        self.PRE        = PRE\n",
    "        self.TMP        = TMP\n",
    "        self.PET        = PET\n",
    "        self.TI         = TI\n",
    "        self.ST         = ST\n",
    "        self.STP        = STP\n",
    "        self.mask       = mask\n",
    "        self.mask_res   = mask_res\n",
    "        self.mask_lon   = mask_lon\n",
    "        self.mask_lat   = mask_lat\n",
    "        self.TI_lon     = TI_lon\n",
    "        self.TI_lat     = TI_lat\n",
    "def get_data_distributed(basin, b):\n",
    "    filepath    = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    # time for calibration and validation\n",
    "    hc_data     = pd.read_csv(filepath, sep='\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start  = pd.to_datetime(f\"{str(cali_start_list[b])}-01-01\")\n",
    "    cali_end    = pd.to_datetime(f\"{str(cali_end_list[b])}-12-31\")\n",
    "    vali_start  = pd.to_datetime(f\"{str(vali_start_list[b])}-01-01\")\n",
    "    vali_end    = pd.to_datetime(f\"{str(vali_end_list[b])}-12-31\")\n",
    "    esim_start  = pd.Timestamp('1980-01-01')\n",
    "    esim_end    = pd.Timestamp('2022-12-31')\n",
    "    # time index\n",
    "    cali_loc    = (hc_data.index >= cali_start) & (hc_data.index <= cali_end)\n",
    "    vali_loc    = (hc_data.index >= vali_start) & (hc_data.index <= vali_end)\n",
    "    esim_loc    = (hc_data.index >= esim_start) & (hc_data.index <= esim_end)\n",
    "\n",
    "    _, _, _, _, _, y_esim = get_data_lumped(basin, b)\n",
    "    # runoff series\n",
    "    y_cali = hc_data.loc[cali_start:cali_end]['RUN'].to_numpy()\n",
    "    y_vali = hc_data.loc[vali_start:vali_end]['RUN'].to_numpy()\n",
    "    # basin grid\n",
    "    basin_mask, mask_lon, mask_lat, mask_bounds, mask_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Basin_Boundary_TIF/{basin}.tif\")\n",
    "    basin_mask[basin_mask >= 0] = 1\n",
    "    # ti\n",
    "    TI, TI_lon, TI_lat, TI_bounds, TI_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Underlying/TI/TI_{basin}.tif\")\n",
    "    # soil_texture\n",
    "    ST, ST_lon, ST_lat, ST_bounds, ST_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Underlying/Soil_Texture/Soil_Texture_{basin}.tif\")\n",
    "    # climatic forcing\n",
    "    PRE, cf_lon, cf_lat = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/PRE_CRU/PRE_{basin}.nc\", 'PRE')\n",
    "    TMP, _, _ = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/TMP_CRU/TMP_{basin}.nc\", 'TMP')\n",
    "    PET, _, _ = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/PET_CRU/PET_{basin}.nc\", 'PET')\n",
    "\n",
    "    PRE_cali = PRE[cali_loc, :, :]\n",
    "    TMP_cali = TMP[cali_loc, :, :]\n",
    "    PET_cali = PET[cali_loc, :, :] * 30.4\n",
    "    PRE_vali = PRE[vali_loc, :, :]\n",
    "    TMP_vali = TMP[vali_loc, :, :]\n",
    "    PET_vali = PET[vali_loc, :, :] * 30.4\n",
    "    PRE_esim = PRE[esim_loc, :, :]\n",
    "    TMP_esim = TMP[esim_loc, :, :]\n",
    "    PET_esim = PET[esim_loc, :, :] * 30.4\n",
    "\n",
    "    x_cali = inputData(PRE_cali, TMP_cali, PET_cali, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    x_vali = inputData(PRE_vali, TMP_vali, PET_vali, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    x_esim = inputData(PRE_esim, TMP_esim, PET_esim, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    return x_cali, y_cali, x_vali, y_vali, x_esim, y_esim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35052a",
   "metadata": {},
   "source": [
    "# è·å–ç‡å®šå‚æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4bd36",
   "metadata": {},
   "source": [
    "## ä¼°è®¡box-coxçš„lambdaå€¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf7a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47952c97a1884a2296f61335ca1550d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d6d791347744e7b00476ca19be7b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average lambda for runoff: -0.08544487026765571\n",
      "Average lambda for AE: 0.5207486965559343\n"
     ]
    }
   ],
   "source": [
    "lambda_list = np.full(len(basin_list), np.nan)\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_pos = y_cali_l[y_cali_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda = boxcox(y_pos)\n",
    "    lambda_list[b] = fitted_lambda\n",
    "lambda_ave_r = np.nanmean(lambda_list)\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_pos = y_esim_l[y_esim_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda = boxcox(y_pos)\n",
    "    lambda_list[b] = fitted_lambda\n",
    "lambda_ave_e = np.nanmean(lambda_list)\n",
    "print(f\"Average lambda for runoff: {lambda_ave_r}\")\n",
    "print(f\"Average lambda for AE: {lambda_ave_e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd4463",
   "metadata": {},
   "source": [
    "# å¾„æµæ¨¡æ‹Ÿè®¡ç®—å¯¹æ•°ä¼¼ç„¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1daf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_gaussian_with_mu(residuals):\n",
    "    n = residuals.size\n",
    "    mu_hat = np.nanmean(residuals)\n",
    "    sigma2_hat = np.nanmean((residuals - mu_hat) ** 2)\n",
    "    lnL = -0.5 * n * (np.log(2*np.pi*sigma2_hat) + 1)\n",
    "    return lnL\n",
    "\n",
    "def information_criteria(lnL: float, k: int, n: int):\n",
    "    AIC = 2*k - 2*lnL\n",
    "    BIC = k*np.log(n) - 2*lnL\n",
    "    return AIC/n, BIC/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475f6ad",
   "metadata": {},
   "source": [
    "# AIACæ–¹æ³•è®¡ç®—å¤šæ¨¡å‹å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96961784",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vars = ['r_lnL', 'r_ic', 'r_re', 'r_kge', 'e_lnL', 'e_ic', 'e_re', 'e_kge', 'r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "results['ic_min'] = np.full(2003, np.nan)\n",
    "results['weighted_KGE'] = np.full(2003, np.nan)\n",
    "results['weighted_RE']  = np.full(2003, np.nan)\n",
    "results['weighted_check'] = np.full(2003, np.nan)\n",
    "\n",
    "params_YM  = pd.read_csv(\"../../Data/Params/03_mYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_AM  = pd.read_csv(\"../../Data/Params/03_abcd_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_DM  = pd.read_csv(\"../../Data/Params/03_DWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_GYM = pd.read_csv(\"../../Data/Params/03_GmYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_transform(y, lam, eps=1e-5):\n",
    "    # Î»=1ï¼šåŸå§‹å€¼ï¼ˆä¸å˜æ¢ï¼‰\n",
    "    # Î»=0ï¼šå¯¹æ•°å˜æ¢\n",
    "    y = y + eps  # ä¿è¯æ­£æ•°\n",
    "    if lam == 0:\n",
    "        return np.log(y)\n",
    "    else:\n",
    "        return (np.power(y, lam) - 1) / lam\n",
    "lambda_ave_r = -0.08544487038241699\n",
    "lambda_ave_e = 0.5207486965559343\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ®‹å·®\n",
    "    y_trans = boxcox_transform(y_cali_l, lambda_ave_r)\n",
    "    r_sim_ym_trans  = boxcox_transform(r_sim_ym, lambda_ave_r)\n",
    "    r_sim_am_trans  = boxcox_transform(r_sim_am, lambda_ave_r)\n",
    "    r_sim_dm_trans  = boxcox_transform(r_sim_dm, lambda_ave_r)\n",
    "    r_sim_gym_trans = boxcox_transform(r_sim_gym, lambda_ave_r)\n",
    "    r_res_ym  = r_sim_ym_trans  - y_trans\n",
    "    r_res_am  = r_sim_am_trans  - y_trans\n",
    "    r_res_dm  = r_sim_dm_trans  - y_trans\n",
    "    r_res_gym = r_sim_gym_trans - y_trans\n",
    "    e_trans = boxcox_transform(y_esim_l, lambda_ave_e)\n",
    "    e_sim_ym_trans  = boxcox_transform(e_sim_ym, lambda_ave_e)\n",
    "    e_sim_am_trans  = boxcox_transform(e_sim_am, lambda_ave_e)\n",
    "    e_sim_dm_trans  = boxcox_transform(e_sim_dm, lambda_ave_e)\n",
    "    e_sim_gym_trans = boxcox_transform(e_sim_gym, lambda_ave_e)\n",
    "    e_res_ym  = e_sim_ym_trans  - e_trans\n",
    "    e_res_am  = e_sim_am_trans  - e_trans\n",
    "    e_res_dm  = e_sim_dm_trans  - e_trans\n",
    "    e_res_gym = e_sim_gym_trans - e_trans\n",
    "    ## è®¡ç®—å¯¹æ•°ä¼¼ç„¶\n",
    "    results['r_lnL_YM'][b]  = loglik_gaussian_with_mu(r_res_ym)\n",
    "    results['r_lnL_AM'][b]  = loglik_gaussian_with_mu(r_res_am)\n",
    "    results['r_lnL_DM'][b]  = loglik_gaussian_with_mu(r_res_dm)\n",
    "    results['r_lnL_GYM'][b] = loglik_gaussian_with_mu(r_res_gym)\n",
    "    results['e_lnL_YM'][b]  = loglik_gaussian_with_mu(e_res_ym)\n",
    "    results['e_lnL_AM'][b]  = loglik_gaussian_with_mu(e_res_am)\n",
    "    results['e_lnL_DM'][b]  = loglik_gaussian_with_mu(e_res_dm)\n",
    "    results['e_lnL_GYM'][b] = loglik_gaussian_with_mu(e_res_gym)\n",
    "    ## è®¡ç®—ä¿¡æ¯å‡†åˆ™\n",
    "    n = len(np.where(~np.isnan(y_cali_l))[0])\n",
    "    k = 7\n",
    "    # æ®‹å·®å¹³æ–¹å’Œ\n",
    "    r_sse_ym  = np.nansum(r_res_ym**2)\n",
    "    r_sse_am  = np.nansum(r_res_am**2)\n",
    "    r_sse_dm  = np.nansum(r_res_dm**2)\n",
    "    r_sse_gym = np.nansum(r_res_gym**2)\n",
    "    e_sse_ym  = np.nansum(e_res_ym**2)\n",
    "    e_sse_am  = np.nansum(e_res_am**2)\n",
    "    e_sse_dm  = np.nansum(e_res_dm**2)\n",
    "    e_sse_gym = np.nansum(e_res_gym**2)\n",
    "    # ä¿¡æ¯å‡†åˆ™\n",
    "    results['r_ic_YM'][b]  = n * np.log(r_sse_ym / n)\n",
    "    results['r_ic_AM'][b]  = n * np.log(r_sse_am / n)\n",
    "    results['r_ic_DM'][b]  = n * np.log(r_sse_dm / n)\n",
    "    results['r_ic_GYM'][b] = n * np.log(r_sse_gym / n)\n",
    "    results['e_ic_YM'][b]  = n * np.log(e_sse_ym / n)\n",
    "    results['e_ic_AM'][b]  = n * np.log(e_sse_am / n)\n",
    "    results['e_ic_DM'][b]  = n * np.log(e_sse_dm / n)\n",
    "    results['e_ic_GYM'][b] = n * np.log(e_sse_gym / n)\n",
    "    ## è®¡ç®—ç›¸å¯¹è¯¯å·®\n",
    "    results['r_re_YM'][b]  = relative_error(y_trans, r_sim_ym_trans)\n",
    "    results['r_re_AM'][b]  = relative_error(y_trans, r_sim_am_trans)\n",
    "    results['r_re_DM'][b]  = relative_error(y_trans, r_sim_dm_trans)\n",
    "    results['r_re_GYM'][b] = relative_error(y_trans, r_sim_gym_trans)\n",
    "    results['e_re_YM'][b]  = relative_error(e_trans, e_sim_ym_trans)\n",
    "    results['e_re_AM'][b]  = relative_error(e_trans, e_sim_am_trans)\n",
    "    results['e_re_DM'][b]  = relative_error(e_trans, e_sim_dm_trans)\n",
    "    results['e_re_GYM'][b] = relative_error(e_trans, e_sim_gym_trans)\n",
    "    ## è®¡ç®—KGE\n",
    "    results['r_kge_YM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_ym_trans)\n",
    "    results['r_kge_AM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_am_trans)\n",
    "    results['r_kge_DM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_dm_trans)\n",
    "    results['r_kge_GYM'][b] = nash_sutcliffe_efficiency(y_trans, r_sim_gym_trans)\n",
    "    results['e_kge_YM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_ym_trans)\n",
    "    results['e_kge_AM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_am_trans)\n",
    "    results['e_kge_DM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_dm_trans)\n",
    "    results['e_kge_GYM'][b] = nash_sutcliffe_efficiency(e_trans, e_sim_gym_trans)\n",
    "    # æœ€å°ä¿¡æ¯å‡†åˆ™\n",
    "    ic_min = np.nanmin([results['r_ic_YM'][b], results['r_ic_AM'][b], results['r_ic_DM'][b], results['r_ic_GYM'][b]])\n",
    "    delta_ic_ym  = results['r_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['r_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['r_ic_DM'][b] - ic_min\n",
    "    delta_ic_gym = results['r_ic_GYM'][b] - ic_min\n",
    "    # è®¡ç®—AICæƒé‡\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_gym = np.exp(-0.5 * delta_ic_gym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "    # æœ€å°ä¿¡æ¯å‡†åˆ™\n",
    "    ic_min = np.nanmin([results['e_ic_YM'][b], results['e_ic_AM'][b], results['e_ic_DM'][b], results['e_ic_GYM'][b]])\n",
    "    delta_ic_ym  = results['e_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['e_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['e_ic_DM'][b] - ic_min\n",
    "    delta_ic_gym = results['e_ic_GYM'][b] - ic_min\n",
    "    # è®¡ç®—AICæƒé‡\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_gym = np.exp(-0.5 * delta_ic_gym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "# ä¿å­˜ç»“æœ\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_AIAC.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de35f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vars = ['r_lnL', 'r_ic', 'r_re', 'r_kge', 'e_lnL', 'e_ic', 'e_re', 'e_kge', 'r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "results['ic_min'] = np.full(2003, np.nan)\n",
    "results['weighted_KGE'] = np.full(2003, np.nan)\n",
    "results['weighted_RE']  = np.full(2003, np.nan)\n",
    "results['weighted_check'] = np.full(2003, np.nan)\n",
    "\n",
    "params_YM  = pd.read_csv(\"../../Data/Params/03_mYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_AM  = pd.read_csv(\"../../Data/Params/03_abcd_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_DM  = pd.read_csv(\"../../Data/Params/03_DWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_GYM = pd.read_csv(\"../../Data/Params/03_GmYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef87170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a64d3610b5d4619840137d9cd4b9493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def boxcox_transform(y, lam, eps=1e-5):\n",
    "    # Î»=1ï¼šåŸå§‹å€¼ï¼ˆä¸å˜æ¢ï¼‰\n",
    "    # Î»=0ï¼šå¯¹æ•°å˜æ¢\n",
    "    y = y + eps  # ä¿è¯æ­£æ•°\n",
    "    if lam == 0:\n",
    "        return np.log(y)\n",
    "    else:\n",
    "        return (np.power(y, lam) - 1) / lam\n",
    "lambda_ave_r = -0.08544487038241699\n",
    "lambda_ave_e = 0.5207486965559343\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_cali_l[y_cali_l < 0] = 0\n",
    "    y_esim_l[y_esim_l < 0] = 0\n",
    "    y_pos_cali = y_cali_l[y_cali_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda_cali = boxcox(y_pos_cali)\n",
    "    y_pos_esim = y_esim_l[y_esim_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda_esim = boxcox(y_pos_esim)\n",
    "\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l + 1e-5, params_YM.loc[basin].values + 1e-5)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l + 1e-5, params_AM.loc[basin].values + 1e-5)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l + 1e-5, params_DM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l + 1e-5, params_YM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l + 1e-5, params_AM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l + 1e-5, params_DM.loc[basin].values + 1e-5)\n",
    "\n",
    "    y_mask = ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm) & ~np.isnan(y_cali_l)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm) & ~np.isnan(y_esim_l)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ®‹å·®\n",
    "    y_trans = boxcox_transform(y_cali_l, fitted_lambda_cali)\n",
    "    r_sim_ym_trans  = boxcox_transform(r_sim_ym, fitted_lambda_cali)\n",
    "    r_sim_am_trans  = boxcox_transform(r_sim_am, fitted_lambda_cali)\n",
    "    r_sim_dm_trans  = boxcox_transform(r_sim_dm, fitted_lambda_cali)\n",
    "    r_res_ym  = r_sim_ym_trans  - y_trans\n",
    "    r_res_am  = r_sim_am_trans  - y_trans\n",
    "    r_res_dm  = r_sim_dm_trans  - y_trans\n",
    "\n",
    "    e_trans = boxcox_transform(y_esim_l, fitted_lambda_esim)\n",
    "    e_sim_ym_trans  = boxcox_transform(e_sim_ym, fitted_lambda_esim)\n",
    "    e_sim_am_trans  = boxcox_transform(e_sim_am, fitted_lambda_esim)\n",
    "    e_sim_dm_trans  = boxcox_transform(e_sim_dm, fitted_lambda_esim)\n",
    "    e_res_ym  = e_sim_ym_trans  - e_trans\n",
    "    e_res_am  = e_sim_am_trans  - e_trans\n",
    "    e_res_dm  = e_sim_dm_trans  - e_trans\n",
    "    ## è®¡ç®—å¯¹æ•°ä¼¼ç„¶\n",
    "    results['r_lnL_YM'][b]  = loglik_gaussian_with_mu(r_res_ym)\n",
    "    results['r_lnL_AM'][b]  = loglik_gaussian_with_mu(r_res_am)\n",
    "    results['r_lnL_DM'][b]  = loglik_gaussian_with_mu(r_res_dm)\n",
    "    results['e_lnL_YM'][b]  = loglik_gaussian_with_mu(e_res_ym)\n",
    "    results['e_lnL_AM'][b]  = loglik_gaussian_with_mu(e_res_am)\n",
    "    results['e_lnL_DM'][b]  = loglik_gaussian_with_mu(e_res_dm)\n",
    "    ## è®¡ç®—ä¿¡æ¯å‡†åˆ™\n",
    "    n = len(np.where(~np.isnan(y_cali_l))[0])\n",
    "    k = 7\n",
    "    # æ®‹å·®å¹³æ–¹å’Œ\n",
    "    r_sse_ym  = np.nansum(r_res_ym**2)\n",
    "    r_sse_am  = np.nansum(r_res_am**2)\n",
    "    r_sse_dm  = np.nansum(r_res_dm**2)\n",
    "\n",
    "    e_sse_ym  = np.nansum(e_res_ym**2)\n",
    "    e_sse_am  = np.nansum(e_res_am**2)\n",
    "    e_sse_dm  = np.nansum(e_res_dm**2)\n",
    "\n",
    "    # ä¿¡æ¯å‡†åˆ™\n",
    "    results['r_ic_YM'][b]  = n * np.log(r_sse_ym / n)\n",
    "    results['r_ic_AM'][b]  = n * np.log(r_sse_am / n)\n",
    "    results['r_ic_DM'][b]  = n * np.log(r_sse_dm / n)\n",
    "\n",
    "    results['e_ic_YM'][b]  = n * np.log(e_sse_ym / n)\n",
    "    results['e_ic_AM'][b]  = n * np.log(e_sse_am / n)\n",
    "    results['e_ic_DM'][b]  = n * np.log(e_sse_dm / n)\n",
    "\n",
    "    ## è®¡ç®—ç›¸å¯¹è¯¯å·®\n",
    "    results['r_re_YM'][b]  = relative_error(y_trans, r_sim_ym_trans)\n",
    "    results['r_re_AM'][b]  = relative_error(y_trans, r_sim_am_trans)\n",
    "    results['r_re_DM'][b]  = relative_error(y_trans, r_sim_dm_trans)\n",
    "\n",
    "    results['e_re_YM'][b]  = relative_error(e_trans, e_sim_ym_trans)\n",
    "    results['e_re_AM'][b]  = relative_error(e_trans, e_sim_am_trans)\n",
    "    results['e_re_DM'][b]  = relative_error(e_trans, e_sim_dm_trans)\n",
    "\n",
    "    ## è®¡ç®—KGE\n",
    "    results['r_kge_YM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_ym_trans)\n",
    "    results['r_kge_AM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_am_trans)\n",
    "    results['r_kge_DM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_dm_trans)\n",
    "\n",
    "    results['e_kge_YM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_ym_trans)\n",
    "    results['e_kge_AM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_am_trans)\n",
    "    results['e_kge_DM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_dm_trans)\n",
    "\n",
    "    # æœ€å°ä¿¡æ¯å‡†åˆ™\n",
    "    ic_min = np.nanmin([results['r_ic_YM'][b], results['r_ic_AM'][b], results['r_ic_DM'][b]])\n",
    "    delta_ic_ym  = results['r_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['r_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['r_ic_DM'][b] - ic_min\n",
    "\n",
    "    # è®¡ç®—AICæƒé‡\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    # æœ€å°ä¿¡æ¯å‡†åˆ™\n",
    "    ic_min = np.nanmin([results['e_ic_YM'][b], results['e_ic_AM'][b], results['e_ic_DM'][b]])\n",
    "    delta_ic_ym  = results['e_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['e_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['e_ic_DM'][b] - ic_min\n",
    "\n",
    "    # è®¡ç®—AICæƒé‡\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "# ä¿å­˜ç»“æœ\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_AIAC_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118640ee",
   "metadata": {},
   "source": [
    "# BMAæ–¹æ³•è®¡ç®—å¤šæ¨¡å‹å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ea66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def fit_bma_em(y, X, max_iter=200, tol=1e-6, verbose=False):\n",
    "    y = np.asarray(y).ravel()\n",
    "    T = len(y)\n",
    "    X = np.asarray(X)\n",
    "    if X.shape[0] != T:\n",
    "        raise ValueError(\"X and y must have the same number of rows\")\n",
    "    T, M = X.shape\n",
    "    w = np.ones(M) / M\n",
    "    a = np.zeros(M)\n",
    "    b = np.ones(M)\n",
    "    sigma = np.ones(M) * max(np.std(y), 1e-3)\n",
    "    loglik_trace = []\n",
    "    for iteration in range(max_iter):\n",
    "        comp_means = (a[:, None] + b[:, None] * X.T).T\n",
    "        pdf = np.empty((T, M))\n",
    "        for i in range(M):\n",
    "            pdf[:, i] = norm.pdf(y, loc=comp_means[:, i], scale=sigma[i] + 1e-12)\n",
    "        weighted_pdf = pdf * w[np.newaxis, :]\n",
    "        denom = np.sum(weighted_pdf, axis=1, keepdims=True)\n",
    "        denom = np.maximum(denom, 1e-300)\n",
    "        z = weighted_pdf / denom\n",
    "        loglik = np.sum(np.log(denom.flatten()))\n",
    "        loglik_trace.append(loglik)\n",
    "        w_new = np.sum(z, axis=0) / T\n",
    "        a_new, b_new, sigma_new = np.zeros_like(a), np.zeros_like(b), np.zeros_like(sigma)\n",
    "        for i in range(M):\n",
    "            wi = z[:, i]\n",
    "            W_sum = np.sum(wi)\n",
    "            if W_sum < 1e-12:\n",
    "                a_new[i], b_new[i], sigma_new[i] = a[i], b[i], sigma[i]\n",
    "                continue\n",
    "            x_i = X[:, i]\n",
    "            x_bar = np.sum(wi * x_i) / W_sum\n",
    "            y_bar = np.sum(wi * y) / W_sum\n",
    "            S_xy = np.sum(wi * (x_i - x_bar) * (y - y_bar))\n",
    "            S_xx = np.sum(wi * (x_i - x_bar)**2)\n",
    "            b_hat = S_xy / S_xx if S_xx != 0 else 0\n",
    "            a_hat = y_bar - b_hat * x_bar\n",
    "            resid = y - (a_hat + b_hat * x_i)\n",
    "            sigma2 = np.sum(wi * resid**2) / W_sum\n",
    "            sigma2 = max(sigma2, 1e-8)\n",
    "            a_new[i], b_new[i], sigma_new[i] = a_hat, b_hat, np.sqrt(sigma2)\n",
    "        w, a, b, sigma = w_new, a_new, b_new, sigma_new\n",
    "        if iteration > 0 and abs(loglik_trace[-1] - loglik_trace[-2]) < tol:\n",
    "            if verbose:\n",
    "                print(\"Converged at iteration\", iteration)\n",
    "            break\n",
    "    comp_means = (a[:, None] + b[:, None] * X.T).T\n",
    "    pred_mean = np.sum(w[np.newaxis, :] * comp_means, axis=1)\n",
    "    pred_second = np.sum(w[np.newaxis, :] * (sigma**2 + comp_means**2), axis=1)\n",
    "    pred_var = np.maximum(pred_second - pred_mean**2, 0.0)\n",
    "    return {\"weights\": w, \"a\": a, \"b\": b, \"sigma\": sigma, \"pred_mean\": pred_mean, \"pred_var\": pred_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1aaca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76ec5cb649a4928b2ce6840fc3e18dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    res = fit_bma_em(Robs, Rsim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "    w_ic_gym = res['weights'][3]\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    res = fit_bma_em(Eobs, Esim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "    w_ic_gym = res['weights'][3]\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_BMA.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8812c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861db25abed4af7b53f9f45667d41b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    res = fit_bma_em(Robs, Rsim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    res = fit_bma_em(Eobs, Esim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_BMA_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5bdfbb",
   "metadata": {},
   "source": [
    "# GRCæ–¹æ³•è®¡ç®—å¤šæ¨¡å‹å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38fbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def grc_weights(X, y, ridge=1e-8):\n",
    "    T, M = X.shape\n",
    "    def obj(w):\n",
    "        preds = X.dot(w)\n",
    "        return np.sum((y - preds)**2) + ridge * np.sum(w**2)\n",
    "    w0 = np.ones(M) / M\n",
    "    cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1) for _ in range(M)]\n",
    "    res = minimize(obj, w0, bounds=bounds, constraints=cons, method='SLSQP', options={'ftol':1e-12, 'maxiter':1000})\n",
    "    if not res.success:\n",
    "        w = np.copy(w0)\n",
    "        lr = 0.01\n",
    "        for it in range(10000):\n",
    "            grad = -2 * X.T.dot(y - X.dot(w)) + 2 * ridge * w\n",
    "            w -= lr * grad\n",
    "            w = np.maximum(w, 0)\n",
    "            s = np.sum(w)\n",
    "            if s == 0:\n",
    "                w = np.ones(M) / M\n",
    "            else:\n",
    "                w = w / s\n",
    "            if np.linalg.norm(grad) * lr < 1e-9:\n",
    "                break\n",
    "        return w, obj(w)\n",
    "    return res.x, res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f925d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ce4ff9c9a24ad287e62e81b420b7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grc, objval = grc_weights(Rsim, Robs)\n",
    "    R_grc = Rsim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "    w_ic_gym = weight_grc['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grc, objval = grc_weights(Esim, Eobs)\n",
    "    E_grc = Esim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "    w_ic_gym = weight_grc['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRC.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8893dac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae6ad6ef1d44f6494bc042d69ae71ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grc, objval = grc_weights(Rsim, Robs)\n",
    "    R_grc = Rsim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grc, objval = grc_weights(Esim, Eobs)\n",
    "    E_grc = Esim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRC_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22000ff4",
   "metadata": {},
   "source": [
    "# GRBæ–¹æ³•è®¡ç®—å¤šæ¨¡å‹å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d258a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grb_weights(X, y):\n",
    "    # ç¡®ä¿è¾“å…¥æ˜¯ numpy æ•°ç»„\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # å¦‚æœ y æ˜¯ä¸€ç»´çš„ï¼Œè½¬ä¸ºåˆ—å‘é‡\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    # æœ€å°äºŒä¹˜ä¼°è®¡\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y\n",
    "    weights = np.linalg.pinv(XtX) @ Xty  # ç”¨ä¼ªé€†æ›´ç¨³å¥\n",
    "    \n",
    "    # è½¬ä¸ºè¡Œå‘é‡\n",
    "    weights = weights.flatten()\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1d7255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904bafe993af4450ac2af4712beae162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grb = grb_weights(Rsim, Robs)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "    w_ic_gym = weight_GRB['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grb = grb_weights(Esim, Eobs)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "    w_ic_gym = weight_GRB['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRB.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234f2842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d938c1734349e0834c54a5e5ded748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grb = grb_weights(Rsim, Robs)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grb = grb_weights(Esim, Eobs)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRB_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57097a3a",
   "metadata": {},
   "source": [
    "# GRAæ–¹æ³•è®¡ç®—å¤šæ¨¡å‹å¹³å‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7183e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gra_weights(X, y):\n",
    "    X_ext = np.column_stack([np.ones(X.shape[0]), X])  # åŠ ä¸€åˆ—æˆªè·é¡¹\n",
    "    beta = np.linalg.lstsq(X_ext, y, rcond=None)[0]\n",
    "    a_hat = beta[0]\n",
    "    w_hat = beta[1:]\n",
    "    y_pred = X_ext.dot(beta)\n",
    "    sse = np.sum((y - y_pred) ** 2)\n",
    "    return a_hat, w_hat, y_pred, sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c5f9021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395e690f9e41482ba28ac7d9309a0436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    a_gra, weights_gra, R_gra, sse = gra_weights(Rsim, Robs)\n",
    "    R_GRA = a_gra + Rsim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "    w_ic_gym = weight_GRA['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    a_gra, weights_gra, E_gra, sse = gra_weights(Esim, Eobs)\n",
    "    E_GRA = a_gra + Esim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "    w_ic_gym = weight_GRA['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRA.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e200457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ddf5a071e24d9f991f946012ad001a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## æµåŸŸæ•°æ®è¯»å–\n",
    "    # å¾„æµæ¨¡æ‹Ÿæ•°æ®\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    # å¾„æµæ¨¡æ‹Ÿ\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # æŠŠ inf æ¢æˆ nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # æ¯è¡Œçš„énanå¹³å‡\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # ç”¨å¯¹åº”è¡Œçš„å‡å€¼æ›¿æ¢nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    a_gra, weights_gra, R_gra, sse = gra_weights(Rsim, Robs)\n",
    "    R_GRA = a_gra + Rsim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    a_gra, weights_gra, E_gra, sse = gra_weights(Esim, Eobs)\n",
    "    E_GRA = a_gra + Esim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRA_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
