{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb85f85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import xarray as xr\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from Water_Blance_Model import mYWBMnlS_RE, abcdnlS_RE, DWBMnlS_RE, GmYWBM_RE\n",
    "from Rewrite_Func import nash_sutcliffe_efficiency, relative_error, kling_gupta_efficiency\n",
    "from numba import float64, njit\n",
    "from numba.experimental import jitclass\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.ndimage import median_filter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import trange\n",
    "from scipy.stats import boxcox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c2c45",
   "metadata": {},
   "source": [
    "## 逐流域算 AIC/BIC & 性能指标 → 判定显著性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd564804",
   "metadata": {},
   "source": [
    "下面给出 **Step 2：逐流域算 AIC/BIC ＋ 性能指标并判断显著性** 的一套 *可直接落地* 的流程和示例代码框架。你只需把自己的观测和模拟结果填进去即可运行。整套流程分成 ❶–❻ 六步；其中 ❹–❻ 是可选进阶，用来给出统计显著性和“优胜概率”判定。\n",
    "\n",
    "---\n",
    "\n",
    "## ❶ 准备数据\n",
    "\n",
    "| 变量            | 说明                  | 建议格式                              |\n",
    "| ------------- | ------------------- | --------------------------------- |\n",
    "| `Q_obs`       | 观测日（或月）径流时间序列       | `numpy.ndarray` 或 `pandas.Series` |\n",
    "| `Q_mod_A/B/C` | 三个模型对同一时段的模拟        | 同上                                |\n",
    "| `n`           | 有效样本长度（去掉缺测后的点数）    | `int`                             |\n",
    "| `k_A/B/C`     | 各模型自由参数个数（含误差方差 σ²） | `int`                             |\n",
    "\n",
    "> 💡 **注意**：如果你对残差做 Box–Cox 变换或 log 变换，记得把 **λ**（Box–Cox 参数）也算进 `k`。\n",
    "\n",
    "---\n",
    "\n",
    "## ❷ 计算对数似然 `lnL`\n",
    "\n",
    "常用假设：\n",
    "\n",
    "* 经过变换的残差 \\~ N (μ, σ²)，独立同分布。\n",
    "* 给定 σ，以残差平方和 (SSR) 直接求对数似然：\n",
    "\n",
    "$$\n",
    "\\ln L = -\\frac{n}{2}\\left[\\ln(2\\pi\\sigma^2)\\right]-\\frac{1}{2\\sigma^2}\\sum_{t=1}^{n} (e_t-μ)^2\n",
    "$$\n",
    "\n",
    "其中\n",
    "\n",
    "$$\n",
    "\\sigma^2 = \\frac{1}{n}\\sum_{t=1}^{n} (e_t)^2\n",
    "$$\n",
    "\n",
    "### Python 函数示例\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def loglik_gaussian(residuals: np.ndarray) -> float:\n",
    "    n = residuals.size\n",
    "    sigma2 = residuals.var(ddof=0)\n",
    "    return -0.5 * n * (np.log(2*np.pi*sigma2) + 1)\n",
    "\n",
    "def loglik_gaussian_with_mu(residuals):\n",
    "    n = residuals.size\n",
    "    mu_hat = residuals.mean()\n",
    "    sigma2_hat = ((residuals - mu_hat) ** 2).mean()\n",
    "    lnL = -0.5 * n * (np.log(2*np.pi*sigma2_hat) + 1)\n",
    "    return lnL, mu_hat, sigma2_hat\n",
    "```\n",
    "\n",
    "当你考虑 μ 和 σ² 都为模型参数时，务必更新参数个数k:\n",
    "\n",
    "$$\n",
    "k = k_{模型参数}+2\n",
    "$$\n",
    "\n",
    "其中“2”来自μ和σ²\n",
    "\n",
    "---\n",
    "\n",
    "## ❸ 计算 AIC / BIC 及 ΔAIC / ΔBIC\n",
    "\n",
    "```python\n",
    "def information_criteria(lnL: float, k: int, n: int):\n",
    "    AIC = 2*k - 2*lnL\n",
    "    BIC = k*np.log(n) - 2*lnL\n",
    "    return AIC, BIC\n",
    "```\n",
    "\n",
    "* **每个流域**算三组 (A, B, C)。\n",
    "* 找到该流域 AIC/BIC 最小的模型，记为 *best*；其余模型的\n",
    "\n",
    "  $$\n",
    "  \\Delta\\text{AIC}_m = \\text{AIC}_m - \\text{AIC}_{best}\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  \\Delta\\text{BIC}_m = \\text{BIC}_m - \\text{BIC}_{best}\n",
    "  $$\n",
    "\n",
    "判定规则（常用阈值）：\n",
    "\n",
    "| ΔAIC/ΔBIC | 0–2    | 2–4 | 4–10 | > 10 |\n",
    "| --------- | ------ | --- | ---- | ---- |\n",
    "| 解释        | 证据几乎相同 | 略好  | 明显好  | 极其显著 |\n",
    "\n",
    "---\n",
    "\n",
    "## ❹ 计算性能指标（NSE、KGE…）\n",
    "\n",
    "```python\n",
    "def nse(obs, sim):\n",
    "    return 1 - (((obs - sim) ** 2).sum() /\n",
    "                ((obs - obs.mean()) ** 2).sum())\n",
    "\n",
    "def kge(obs, sim):\n",
    "    r   = np.corrcoef(obs, sim)[0,1]\n",
    "    alpha = sim.std() / obs.std()\n",
    "    beta  = sim.mean() / obs.mean()\n",
    "    return 1 - np.sqrt((r-1)**2 + (alpha-1)**2 + (beta-1)**2)\n",
    "```\n",
    "\n",
    "保存到同一个 `DataFrame`，后面可直接做差：\n",
    "\n",
    "$$\n",
    "\\Delta\\text{NSE}_{C-B} = \\text{NSE}_C - \\text{NSE}_B\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## ❺ 判定差异显著性（两条思路，至少选其一）\n",
    "\n",
    "### A. 信息准则阈值法（快速）\n",
    "\n",
    "* 在每个流域：若 **ΔBIC<4**，视为“差别不足”；\n",
    "  若 **ΔBIC ≥ 4** 且 C 最佳 → 记作 “C 显著优”；\n",
    "  若 C 不是最佳 → “C 不优”。\n",
    "* 优缺点：简单，但只依赖似然，不看 NSE/KGE。\n",
    "\n",
    "### B. Bootstrapped 性能差异置信区间（更稳健）\n",
    "\n",
    "1. **对齐日期**：保持 `obs` 与 `sim` 同长。\n",
    "2. **块自助法 (block bootstrap)**：\n",
    "\n",
    "   ```python\n",
    "   import random\n",
    "   block = 30  # 30 天块\n",
    "   n_bs  = 1000\n",
    "   diff  = []\n",
    "   for _ in range(n_bs):\n",
    "       idx = []\n",
    "       while len(idx) < len(obs):\n",
    "           start = random.randint(0, len(obs)-block)\n",
    "           idx.extend(range(start, start+block))\n",
    "       idx = idx[:len(obs)]\n",
    "       diff.append(nse(obs[idx], simC[idx]) -\n",
    "                   nse(obs[idx], simB[idx]))\n",
    "   lo, hi = np.percentile(diff, [2.5, 97.5])\n",
    "   signif = (lo > 0) or (hi < 0)   # True→显著\n",
    "   ```\n",
    "3. 统计 2003 个流域里 `signif==True` 且 C 优的比例。\n",
    "\n",
    "---\n",
    "\n",
    "## ❻ （可选）转化为 **后验模型概率 PMP** 以便后续 BMA\n",
    "\n",
    "模型权重：\n",
    "\n",
    "$$\n",
    "w_m = \\exp\\!\\left(-\\frac{1}{2}\\,\\Delta\\text{BIC}_m\\right),\\qquad\n",
    "\\text{PMP}_m = \\frac{w_m}{\\sum_{j} w_j}\n",
    "$$\n",
    "\n",
    "一步 Python：\n",
    "\n",
    "```python\n",
    "weights = np.exp(-0.5 * delta_BIC_array)\n",
    "PMP     = weights / weights.sum(axis=1, keepdims=True)\n",
    "```\n",
    "\n",
    "到此，一个包含字段\n",
    "\n",
    "\\| basin\\_id | best\\_model | ΔAIC\\_A/B/C | ΔBIC\\_A/B/C | NSE\\_A/B/C | KGE\\_A/B/C | signif\\_CvsB | PMP\\_A/B/C |\n",
    "\n",
    "的总表（`DataFrame` 或 `Parquet`）就准备好了，可用于后续 **Step 3 交叉验证 + BMA** 以及帕累托分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404f799",
   "metadata": {},
   "source": [
    "# 定义流域信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ccaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取流域信息\n",
    "basin_info      = pd.read_excel('../../Data/Basin_Selection/All_Selected_Basins.xlsx')\n",
    "basin_list      = basin_info['stat_num']\n",
    "cali_start_list = basin_info['cali_start']\n",
    "cali_end_list   = basin_info['cali_end']\n",
    "vali_start_list = basin_info['vali_start']\n",
    "vali_end_list   = basin_info['vali_end']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8290ef4",
   "metadata": {},
   "source": [
    "# 定义数据读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85d488bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集总式模型数据读取\n",
    "def get_data_lumped(basin, basin_idx):\n",
    "    filepath = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    hc_data = pd.read_csv(filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start = pd.to_datetime(f\"{str(cali_start_list[basin_idx])}-01-01\")\n",
    "    cali_end   = pd.to_datetime(f\"{str(cali_end_list[basin_idx])}-12-31\")\n",
    "    vali_start = pd.to_datetime(f\"{str(vali_start_list[basin_idx])}-01-01\")\n",
    "    vali_end   = pd.to_datetime(f\"{str(vali_end_list[basin_idx])}-12-31\")\n",
    "    esim_start = pd.Timestamp('1980-01-01')\n",
    "    esim_end   = pd.Timestamp('2022-12-31')\n",
    "\n",
    "    cali_data = hc_data.loc[cali_start : cali_end]\n",
    "    vali_data = hc_data.loc[vali_start : vali_end]\n",
    "    esim_data = hc_data.loc[esim_start : esim_end]\n",
    "\n",
    "    x_cali = cali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "    y_cali = cali_data['RUN'].values\n",
    "    x_vali = vali_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "    y_vali = vali_data['RUN'].values\n",
    "    x_esim = esim_data[['PRE_CRU', 'TMP_CRU', 'PET_CRU']].values + 1e-6\n",
    "\n",
    "    ae_filepath = f\"../../../2025_03_Hydrological_Models/Data/AE/AE_{basin}.txt\"\n",
    "    ae_obs = pd.read_csv(ae_filepath, sep = '\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "\n",
    "    y_esim = ae_obs['AE'].values\n",
    "    return x_cali, y_cali, x_vali, y_vali, x_esim, y_esim\n",
    "\n",
    "STP = pd.read_excel(\"../../../2025_03_Hydrological_Models/Raw_Data/D_TEXTURE_USDA.xlsx\")\n",
    "STP = STP[['CODE', 's', 'fc', 'wp']].to_numpy()\n",
    "\n",
    "def read_georaster(filepath):\n",
    "    with rasterio.open(filepath) as src:\n",
    "        temp_data = src.read(1)\n",
    "        new_data = temp_data.copy().astype(np.float64)\n",
    "        new_data[new_data < 0] = np.nan\n",
    "        # 获取经纬度范围\n",
    "        bounds = src.bounds\n",
    "        # 获取分辨率\n",
    "        res = src.res\n",
    "        # 生成经纬度坐标\n",
    "        lon = np.round(np.arange(bounds.left + res[0] / 2, bounds.right, res[0]), 3)\n",
    "        lat = np.round(np.arange(bounds.top - res[1] / 2, bounds.bottom, -res[1]), 3)\n",
    "    return new_data, lon, lat, bounds, res[0]\n",
    "\n",
    "def read_nc(filepath, varname):\n",
    "    cf_info = Dataset(filepath)\n",
    "    cf_data = np.rot90(np.flip(cf_info.variables[varname][:].data, axis=1), k = -1, axes=(1 ,2))\n",
    "    cf_lon = cf_info.variables['lon'][:].data\n",
    "    cf_lat = cf_info.variables['lat'][:].data\n",
    "    cf_info.close()\n",
    "    return cf_data, cf_lon, cf_lat\n",
    "\n",
    "spec = [\n",
    "    ('PRE',      float64[:, :, :]),\n",
    "    ('TMP',      float64[:, :, :]),\n",
    "    ('PET',      float64[:, :, :]),\n",
    "    ('TI',       float64[:, :]),\n",
    "    ('ST',       float64[:, :]),\n",
    "    ('STP',      float64[:, :]),\n",
    "    ('mask',     float64[:, :]),\n",
    "    ('mask_res', float64),\n",
    "    ('mask_lon', float64[:]),\n",
    "    ('mask_lat', float64[:]),\n",
    "    ('TI_lon',   float64[:]),\n",
    "    ('TI_lat',   float64[:]),\n",
    "]\n",
    "@jitclass(spec)\n",
    "class inputData:\n",
    "    def __init__(self, PRE, TMP, PET, TI, ST, STP, mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat):\n",
    "        self.PRE        = PRE\n",
    "        self.TMP        = TMP\n",
    "        self.PET        = PET\n",
    "        self.TI         = TI\n",
    "        self.ST         = ST\n",
    "        self.STP        = STP\n",
    "        self.mask       = mask\n",
    "        self.mask_res   = mask_res\n",
    "        self.mask_lon   = mask_lon\n",
    "        self.mask_lat   = mask_lat\n",
    "        self.TI_lon     = TI_lon\n",
    "        self.TI_lat     = TI_lat\n",
    "def get_data_distributed(basin, b):\n",
    "    filepath    = f\"../../../2025_03_Hydrological_Models/Data/New_Hydro_Climatic/NHC_{basin}.txt\"\n",
    "    # time for calibration and validation\n",
    "    hc_data     = pd.read_csv(filepath, sep='\\t', header=0, index_col='Time', parse_dates=['Time'])\n",
    "    cali_start  = pd.to_datetime(f\"{str(cali_start_list[b])}-01-01\")\n",
    "    cali_end    = pd.to_datetime(f\"{str(cali_end_list[b])}-12-31\")\n",
    "    vali_start  = pd.to_datetime(f\"{str(vali_start_list[b])}-01-01\")\n",
    "    vali_end    = pd.to_datetime(f\"{str(vali_end_list[b])}-12-31\")\n",
    "    esim_start  = pd.Timestamp('1980-01-01')\n",
    "    esim_end    = pd.Timestamp('2022-12-31')\n",
    "    # time index\n",
    "    cali_loc    = (hc_data.index >= cali_start) & (hc_data.index <= cali_end)\n",
    "    vali_loc    = (hc_data.index >= vali_start) & (hc_data.index <= vali_end)\n",
    "    esim_loc    = (hc_data.index >= esim_start) & (hc_data.index <= esim_end)\n",
    "\n",
    "    _, _, _, _, _, y_esim = get_data_lumped(basin, b)\n",
    "    # runoff series\n",
    "    y_cali = hc_data.loc[cali_start:cali_end]['RUN'].to_numpy()\n",
    "    y_vali = hc_data.loc[vali_start:vali_end]['RUN'].to_numpy()\n",
    "    # basin grid\n",
    "    basin_mask, mask_lon, mask_lat, mask_bounds, mask_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Basin_Boundary_TIF/{basin}.tif\")\n",
    "    basin_mask[basin_mask >= 0] = 1\n",
    "    # ti\n",
    "    TI, TI_lon, TI_lat, TI_bounds, TI_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Underlying/TI/TI_{basin}.tif\")\n",
    "    # soil_texture\n",
    "    ST, ST_lon, ST_lat, ST_bounds, ST_res = read_georaster(f\"../../../2025_03_Hydrological_Models/Data/Underlying/Soil_Texture/Soil_Texture_{basin}.tif\")\n",
    "    # climatic forcing\n",
    "    PRE, cf_lon, cf_lat = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/PRE_CRU/PRE_{basin}.nc\", 'PRE')\n",
    "    TMP, _, _ = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/TMP_CRU/TMP_{basin}.nc\", 'TMP')\n",
    "    PET, _, _ = read_nc(f\"../../../2025_03_Hydrological_Models/Data/CRU/PET_CRU/PET_{basin}.nc\", 'PET')\n",
    "\n",
    "    PRE_cali = PRE[cali_loc, :, :]\n",
    "    TMP_cali = TMP[cali_loc, :, :]\n",
    "    PET_cali = PET[cali_loc, :, :] * 30.4\n",
    "    PRE_vali = PRE[vali_loc, :, :]\n",
    "    TMP_vali = TMP[vali_loc, :, :]\n",
    "    PET_vali = PET[vali_loc, :, :] * 30.4\n",
    "    PRE_esim = PRE[esim_loc, :, :]\n",
    "    TMP_esim = TMP[esim_loc, :, :]\n",
    "    PET_esim = PET[esim_loc, :, :] * 30.4\n",
    "\n",
    "    x_cali = inputData(PRE_cali, TMP_cali, PET_cali, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    x_vali = inputData(PRE_vali, TMP_vali, PET_vali, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    x_esim = inputData(PRE_esim, TMP_esim, PET_esim, TI, ST, STP, basin_mask, mask_res, mask_lon, mask_lat, TI_lon, TI_lat)\n",
    "    return x_cali, y_cali, x_vali, y_vali, x_esim, y_esim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d35052a",
   "metadata": {},
   "source": [
    "# 获取率定参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b4bd36",
   "metadata": {},
   "source": [
    "## 估计box-cox的lambda值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf7a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47952c97a1884a2296f61335ca1550d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d6d791347744e7b00476ca19be7b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average lambda for runoff: -0.08544487026765571\n",
      "Average lambda for AE: 0.5207486965559343\n"
     ]
    }
   ],
   "source": [
    "lambda_list = np.full(len(basin_list), np.nan)\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_pos = y_cali_l[y_cali_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda = boxcox(y_pos)\n",
    "    lambda_list[b] = fitted_lambda\n",
    "lambda_ave_r = np.nanmean(lambda_list)\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_pos = y_esim_l[y_esim_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda = boxcox(y_pos)\n",
    "    lambda_list[b] = fitted_lambda\n",
    "lambda_ave_e = np.nanmean(lambda_list)\n",
    "print(f\"Average lambda for runoff: {lambda_ave_r}\")\n",
    "print(f\"Average lambda for AE: {lambda_ave_e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd4463",
   "metadata": {},
   "source": [
    "# 径流模拟计算对数似然"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1daf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loglik_gaussian_with_mu(residuals):\n",
    "    n = residuals.size\n",
    "    mu_hat = np.nanmean(residuals)\n",
    "    sigma2_hat = np.nanmean((residuals - mu_hat) ** 2)\n",
    "    lnL = -0.5 * n * (np.log(2*np.pi*sigma2_hat) + 1)\n",
    "    return lnL\n",
    "\n",
    "def information_criteria(lnL: float, k: int, n: int):\n",
    "    AIC = 2*k - 2*lnL\n",
    "    BIC = k*np.log(n) - 2*lnL\n",
    "    return AIC/n, BIC/n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475f6ad",
   "metadata": {},
   "source": [
    "# AIAC方法计算多模型平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96961784",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vars = ['r_lnL', 'r_ic', 'r_re', 'r_kge', 'e_lnL', 'e_ic', 'e_re', 'e_kge', 'r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "results['ic_min'] = np.full(2003, np.nan)\n",
    "results['weighted_KGE'] = np.full(2003, np.nan)\n",
    "results['weighted_RE']  = np.full(2003, np.nan)\n",
    "results['weighted_check'] = np.full(2003, np.nan)\n",
    "\n",
    "params_YM  = pd.read_csv(\"../../Data/Params/03_mYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_AM  = pd.read_csv(\"../../Data/Params/03_abcd_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_DM  = pd.read_csv(\"../../Data/Params/03_DWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_GYM = pd.read_csv(\"../../Data/Params/03_GmYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1e739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcox_transform(y, lam, eps=1e-5):\n",
    "    # λ=1：原始值（不变换）\n",
    "    # λ=0：对数变换\n",
    "    y = y + eps  # 保证正数\n",
    "    if lam == 0:\n",
    "        return np.log(y)\n",
    "    else:\n",
    "        return (np.power(y, lam) - 1) / lam\n",
    "lambda_ave_r = -0.08544487038241699\n",
    "lambda_ave_e = 0.5207486965559343\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "    # 径流模拟残差\n",
    "    y_trans = boxcox_transform(y_cali_l, lambda_ave_r)\n",
    "    r_sim_ym_trans  = boxcox_transform(r_sim_ym, lambda_ave_r)\n",
    "    r_sim_am_trans  = boxcox_transform(r_sim_am, lambda_ave_r)\n",
    "    r_sim_dm_trans  = boxcox_transform(r_sim_dm, lambda_ave_r)\n",
    "    r_sim_gym_trans = boxcox_transform(r_sim_gym, lambda_ave_r)\n",
    "    r_res_ym  = r_sim_ym_trans  - y_trans\n",
    "    r_res_am  = r_sim_am_trans  - y_trans\n",
    "    r_res_dm  = r_sim_dm_trans  - y_trans\n",
    "    r_res_gym = r_sim_gym_trans - y_trans\n",
    "    e_trans = boxcox_transform(y_esim_l, lambda_ave_e)\n",
    "    e_sim_ym_trans  = boxcox_transform(e_sim_ym, lambda_ave_e)\n",
    "    e_sim_am_trans  = boxcox_transform(e_sim_am, lambda_ave_e)\n",
    "    e_sim_dm_trans  = boxcox_transform(e_sim_dm, lambda_ave_e)\n",
    "    e_sim_gym_trans = boxcox_transform(e_sim_gym, lambda_ave_e)\n",
    "    e_res_ym  = e_sim_ym_trans  - e_trans\n",
    "    e_res_am  = e_sim_am_trans  - e_trans\n",
    "    e_res_dm  = e_sim_dm_trans  - e_trans\n",
    "    e_res_gym = e_sim_gym_trans - e_trans\n",
    "    ## 计算对数似然\n",
    "    results['r_lnL_YM'][b]  = loglik_gaussian_with_mu(r_res_ym)\n",
    "    results['r_lnL_AM'][b]  = loglik_gaussian_with_mu(r_res_am)\n",
    "    results['r_lnL_DM'][b]  = loglik_gaussian_with_mu(r_res_dm)\n",
    "    results['r_lnL_GYM'][b] = loglik_gaussian_with_mu(r_res_gym)\n",
    "    results['e_lnL_YM'][b]  = loglik_gaussian_with_mu(e_res_ym)\n",
    "    results['e_lnL_AM'][b]  = loglik_gaussian_with_mu(e_res_am)\n",
    "    results['e_lnL_DM'][b]  = loglik_gaussian_with_mu(e_res_dm)\n",
    "    results['e_lnL_GYM'][b] = loglik_gaussian_with_mu(e_res_gym)\n",
    "    ## 计算信息准则\n",
    "    n = len(np.where(~np.isnan(y_cali_l))[0])\n",
    "    k = 7\n",
    "    # 残差平方和\n",
    "    r_sse_ym  = np.nansum(r_res_ym**2)\n",
    "    r_sse_am  = np.nansum(r_res_am**2)\n",
    "    r_sse_dm  = np.nansum(r_res_dm**2)\n",
    "    r_sse_gym = np.nansum(r_res_gym**2)\n",
    "    e_sse_ym  = np.nansum(e_res_ym**2)\n",
    "    e_sse_am  = np.nansum(e_res_am**2)\n",
    "    e_sse_dm  = np.nansum(e_res_dm**2)\n",
    "    e_sse_gym = np.nansum(e_res_gym**2)\n",
    "    # 信息准则\n",
    "    results['r_ic_YM'][b]  = n * np.log(r_sse_ym / n)\n",
    "    results['r_ic_AM'][b]  = n * np.log(r_sse_am / n)\n",
    "    results['r_ic_DM'][b]  = n * np.log(r_sse_dm / n)\n",
    "    results['r_ic_GYM'][b] = n * np.log(r_sse_gym / n)\n",
    "    results['e_ic_YM'][b]  = n * np.log(e_sse_ym / n)\n",
    "    results['e_ic_AM'][b]  = n * np.log(e_sse_am / n)\n",
    "    results['e_ic_DM'][b]  = n * np.log(e_sse_dm / n)\n",
    "    results['e_ic_GYM'][b] = n * np.log(e_sse_gym / n)\n",
    "    ## 计算相对误差\n",
    "    results['r_re_YM'][b]  = relative_error(y_trans, r_sim_ym_trans)\n",
    "    results['r_re_AM'][b]  = relative_error(y_trans, r_sim_am_trans)\n",
    "    results['r_re_DM'][b]  = relative_error(y_trans, r_sim_dm_trans)\n",
    "    results['r_re_GYM'][b] = relative_error(y_trans, r_sim_gym_trans)\n",
    "    results['e_re_YM'][b]  = relative_error(e_trans, e_sim_ym_trans)\n",
    "    results['e_re_AM'][b]  = relative_error(e_trans, e_sim_am_trans)\n",
    "    results['e_re_DM'][b]  = relative_error(e_trans, e_sim_dm_trans)\n",
    "    results['e_re_GYM'][b] = relative_error(e_trans, e_sim_gym_trans)\n",
    "    ## 计算KGE\n",
    "    results['r_kge_YM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_ym_trans)\n",
    "    results['r_kge_AM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_am_trans)\n",
    "    results['r_kge_DM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_dm_trans)\n",
    "    results['r_kge_GYM'][b] = nash_sutcliffe_efficiency(y_trans, r_sim_gym_trans)\n",
    "    results['e_kge_YM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_ym_trans)\n",
    "    results['e_kge_AM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_am_trans)\n",
    "    results['e_kge_DM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_dm_trans)\n",
    "    results['e_kge_GYM'][b] = nash_sutcliffe_efficiency(e_trans, e_sim_gym_trans)\n",
    "    # 最小信息准则\n",
    "    ic_min = np.nanmin([results['r_ic_YM'][b], results['r_ic_AM'][b], results['r_ic_DM'][b], results['r_ic_GYM'][b]])\n",
    "    delta_ic_ym  = results['r_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['r_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['r_ic_DM'][b] - ic_min\n",
    "    delta_ic_gym = results['r_ic_GYM'][b] - ic_min\n",
    "    # 计算AIC权重\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_gym = np.exp(-0.5 * delta_ic_gym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "    # 最小信息准则\n",
    "    ic_min = np.nanmin([results['e_ic_YM'][b], results['e_ic_AM'][b], results['e_ic_DM'][b], results['e_ic_GYM'][b]])\n",
    "    delta_ic_ym  = results['e_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['e_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['e_ic_DM'][b] - ic_min\n",
    "    delta_ic_gym = results['e_ic_GYM'][b] - ic_min\n",
    "    # 计算AIC权重\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    w_ic_gym = np.exp(-0.5 * delta_ic_gym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm) + np.exp(-0.5 * delta_ic_gym))\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "# 保存结果\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_AIAC.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de35f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_vars = ['r_lnL', 'r_ic', 'r_re', 'r_kge', 'e_lnL', 'e_ic', 'e_re', 'e_kge', 'r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "results['ic_min'] = np.full(2003, np.nan)\n",
    "results['weighted_KGE'] = np.full(2003, np.nan)\n",
    "results['weighted_RE']  = np.full(2003, np.nan)\n",
    "results['weighted_check'] = np.full(2003, np.nan)\n",
    "\n",
    "params_YM  = pd.read_csv(\"../../Data/Params/03_mYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_AM  = pd.read_csv(\"../../Data/Params/03_abcd_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_DM  = pd.read_csv(\"../../Data/Params/03_DWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')\n",
    "params_GYM = pd.read_csv(\"../../Data/Params/03_GmYWBM_Best_Params_CF.txt\", sep=\"\\t\", index_col='stat_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aef87170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a64d3610b5d4619840137d9cd4b9493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def boxcox_transform(y, lam, eps=1e-5):\n",
    "    # λ=1：原始值（不变换）\n",
    "    # λ=0：对数变换\n",
    "    y = y + eps  # 保证正数\n",
    "    if lam == 0:\n",
    "        return np.log(y)\n",
    "    else:\n",
    "        return (np.power(y, lam) - 1) / lam\n",
    "lambda_ave_r = -0.08544487038241699\n",
    "lambda_ave_e = 0.5207486965559343\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    y_cali_l[y_cali_l < 0] = 0\n",
    "    y_esim_l[y_esim_l < 0] = 0\n",
    "    y_pos_cali = y_cali_l[y_cali_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda_cali = boxcox(y_pos_cali)\n",
    "    y_pos_esim = y_esim_l[y_esim_l > 0] + 1e-5\n",
    "    y_trans, fitted_lambda_esim = boxcox(y_pos_esim)\n",
    "\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l + 1e-5, params_YM.loc[basin].values + 1e-5)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l + 1e-5, params_AM.loc[basin].values + 1e-5)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l + 1e-5, params_DM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l + 1e-5, params_YM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l + 1e-5, params_AM.loc[basin].values + 1e-5)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l + 1e-5, params_DM.loc[basin].values + 1e-5)\n",
    "\n",
    "    y_mask = ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm) & ~np.isnan(y_cali_l)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm) & ~np.isnan(y_esim_l)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    # 径流模拟残差\n",
    "    y_trans = boxcox_transform(y_cali_l, fitted_lambda_cali)\n",
    "    r_sim_ym_trans  = boxcox_transform(r_sim_ym, fitted_lambda_cali)\n",
    "    r_sim_am_trans  = boxcox_transform(r_sim_am, fitted_lambda_cali)\n",
    "    r_sim_dm_trans  = boxcox_transform(r_sim_dm, fitted_lambda_cali)\n",
    "    r_res_ym  = r_sim_ym_trans  - y_trans\n",
    "    r_res_am  = r_sim_am_trans  - y_trans\n",
    "    r_res_dm  = r_sim_dm_trans  - y_trans\n",
    "\n",
    "    e_trans = boxcox_transform(y_esim_l, fitted_lambda_esim)\n",
    "    e_sim_ym_trans  = boxcox_transform(e_sim_ym, fitted_lambda_esim)\n",
    "    e_sim_am_trans  = boxcox_transform(e_sim_am, fitted_lambda_esim)\n",
    "    e_sim_dm_trans  = boxcox_transform(e_sim_dm, fitted_lambda_esim)\n",
    "    e_res_ym  = e_sim_ym_trans  - e_trans\n",
    "    e_res_am  = e_sim_am_trans  - e_trans\n",
    "    e_res_dm  = e_sim_dm_trans  - e_trans\n",
    "    ## 计算对数似然\n",
    "    results['r_lnL_YM'][b]  = loglik_gaussian_with_mu(r_res_ym)\n",
    "    results['r_lnL_AM'][b]  = loglik_gaussian_with_mu(r_res_am)\n",
    "    results['r_lnL_DM'][b]  = loglik_gaussian_with_mu(r_res_dm)\n",
    "    results['e_lnL_YM'][b]  = loglik_gaussian_with_mu(e_res_ym)\n",
    "    results['e_lnL_AM'][b]  = loglik_gaussian_with_mu(e_res_am)\n",
    "    results['e_lnL_DM'][b]  = loglik_gaussian_with_mu(e_res_dm)\n",
    "    ## 计算信息准则\n",
    "    n = len(np.where(~np.isnan(y_cali_l))[0])\n",
    "    k = 7\n",
    "    # 残差平方和\n",
    "    r_sse_ym  = np.nansum(r_res_ym**2)\n",
    "    r_sse_am  = np.nansum(r_res_am**2)\n",
    "    r_sse_dm  = np.nansum(r_res_dm**2)\n",
    "\n",
    "    e_sse_ym  = np.nansum(e_res_ym**2)\n",
    "    e_sse_am  = np.nansum(e_res_am**2)\n",
    "    e_sse_dm  = np.nansum(e_res_dm**2)\n",
    "\n",
    "    # 信息准则\n",
    "    results['r_ic_YM'][b]  = n * np.log(r_sse_ym / n)\n",
    "    results['r_ic_AM'][b]  = n * np.log(r_sse_am / n)\n",
    "    results['r_ic_DM'][b]  = n * np.log(r_sse_dm / n)\n",
    "\n",
    "    results['e_ic_YM'][b]  = n * np.log(e_sse_ym / n)\n",
    "    results['e_ic_AM'][b]  = n * np.log(e_sse_am / n)\n",
    "    results['e_ic_DM'][b]  = n * np.log(e_sse_dm / n)\n",
    "\n",
    "    ## 计算相对误差\n",
    "    results['r_re_YM'][b]  = relative_error(y_trans, r_sim_ym_trans)\n",
    "    results['r_re_AM'][b]  = relative_error(y_trans, r_sim_am_trans)\n",
    "    results['r_re_DM'][b]  = relative_error(y_trans, r_sim_dm_trans)\n",
    "\n",
    "    results['e_re_YM'][b]  = relative_error(e_trans, e_sim_ym_trans)\n",
    "    results['e_re_AM'][b]  = relative_error(e_trans, e_sim_am_trans)\n",
    "    results['e_re_DM'][b]  = relative_error(e_trans, e_sim_dm_trans)\n",
    "\n",
    "    ## 计算KGE\n",
    "    results['r_kge_YM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_ym_trans)\n",
    "    results['r_kge_AM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_am_trans)\n",
    "    results['r_kge_DM'][b]  = nash_sutcliffe_efficiency(y_trans, r_sim_dm_trans)\n",
    "\n",
    "    results['e_kge_YM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_ym_trans)\n",
    "    results['e_kge_AM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_am_trans)\n",
    "    results['e_kge_DM'][b]  = nash_sutcliffe_efficiency(e_trans, e_sim_dm_trans)\n",
    "\n",
    "    # 最小信息准则\n",
    "    ic_min = np.nanmin([results['r_ic_YM'][b], results['r_ic_AM'][b], results['r_ic_DM'][b]])\n",
    "    delta_ic_ym  = results['r_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['r_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['r_ic_DM'][b] - ic_min\n",
    "\n",
    "    # 计算AIC权重\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    # 最小信息准则\n",
    "    ic_min = np.nanmin([results['e_ic_YM'][b], results['e_ic_AM'][b], results['e_ic_DM'][b]])\n",
    "    delta_ic_ym  = results['e_ic_YM'][b] - ic_min\n",
    "    delta_ic_am  = results['e_ic_AM'][b] - ic_min\n",
    "    delta_ic_dm  = results['e_ic_DM'][b] - ic_min\n",
    "\n",
    "    # 计算AIC权重\n",
    "    w_ic_ym  = np.exp(-0.5 * delta_ic_ym) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_am  = np.exp(-0.5 * delta_ic_am) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "    w_ic_dm  = np.exp(-0.5 * delta_ic_dm) / (np.exp(-0.5 * delta_ic_ym) + np.exp(-0.5 * delta_ic_am) + np.exp(-0.5 * delta_ic_dm))\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "# 保存结果\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_AIAC_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118640ee",
   "metadata": {},
   "source": [
    "# BMA方法计算多模型平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23ea66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def fit_bma_em(y, X, max_iter=200, tol=1e-6, verbose=False):\n",
    "    y = np.asarray(y).ravel()\n",
    "    T = len(y)\n",
    "    X = np.asarray(X)\n",
    "    if X.shape[0] != T:\n",
    "        raise ValueError(\"X and y must have the same number of rows\")\n",
    "    T, M = X.shape\n",
    "    w = np.ones(M) / M\n",
    "    a = np.zeros(M)\n",
    "    b = np.ones(M)\n",
    "    sigma = np.ones(M) * max(np.std(y), 1e-3)\n",
    "    loglik_trace = []\n",
    "    for iteration in range(max_iter):\n",
    "        comp_means = (a[:, None] + b[:, None] * X.T).T\n",
    "        pdf = np.empty((T, M))\n",
    "        for i in range(M):\n",
    "            pdf[:, i] = norm.pdf(y, loc=comp_means[:, i], scale=sigma[i] + 1e-12)\n",
    "        weighted_pdf = pdf * w[np.newaxis, :]\n",
    "        denom = np.sum(weighted_pdf, axis=1, keepdims=True)\n",
    "        denom = np.maximum(denom, 1e-300)\n",
    "        z = weighted_pdf / denom\n",
    "        loglik = np.sum(np.log(denom.flatten()))\n",
    "        loglik_trace.append(loglik)\n",
    "        w_new = np.sum(z, axis=0) / T\n",
    "        a_new, b_new, sigma_new = np.zeros_like(a), np.zeros_like(b), np.zeros_like(sigma)\n",
    "        for i in range(M):\n",
    "            wi = z[:, i]\n",
    "            W_sum = np.sum(wi)\n",
    "            if W_sum < 1e-12:\n",
    "                a_new[i], b_new[i], sigma_new[i] = a[i], b[i], sigma[i]\n",
    "                continue\n",
    "            x_i = X[:, i]\n",
    "            x_bar = np.sum(wi * x_i) / W_sum\n",
    "            y_bar = np.sum(wi * y) / W_sum\n",
    "            S_xy = np.sum(wi * (x_i - x_bar) * (y - y_bar))\n",
    "            S_xx = np.sum(wi * (x_i - x_bar)**2)\n",
    "            b_hat = S_xy / S_xx if S_xx != 0 else 0\n",
    "            a_hat = y_bar - b_hat * x_bar\n",
    "            resid = y - (a_hat + b_hat * x_i)\n",
    "            sigma2 = np.sum(wi * resid**2) / W_sum\n",
    "            sigma2 = max(sigma2, 1e-8)\n",
    "            a_new[i], b_new[i], sigma_new[i] = a_hat, b_hat, np.sqrt(sigma2)\n",
    "        w, a, b, sigma = w_new, a_new, b_new, sigma_new\n",
    "        if iteration > 0 and abs(loglik_trace[-1] - loglik_trace[-2]) < tol:\n",
    "            if verbose:\n",
    "                print(\"Converged at iteration\", iteration)\n",
    "            break\n",
    "    comp_means = (a[:, None] + b[:, None] * X.T).T\n",
    "    pred_mean = np.sum(w[np.newaxis, :] * comp_means, axis=1)\n",
    "    pred_second = np.sum(w[np.newaxis, :] * (sigma**2 + comp_means**2), axis=1)\n",
    "    pred_var = np.maximum(pred_second - pred_mean**2, 0.0)\n",
    "    return {\"weights\": w, \"a\": a, \"b\": b, \"sigma\": sigma, \"pred_mean\": pred_mean, \"pred_var\": pred_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1aaca4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f76ec5cb649a4928b2ce6840fc3e18dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    res = fit_bma_em(Robs, Rsim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "    w_ic_gym = res['weights'][3]\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    res = fit_bma_em(Eobs, Esim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "    w_ic_gym = res['weights'][3]\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_BMA.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8812c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9861db25abed4af7b53f9f45667d41b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    res = fit_bma_em(Robs, Rsim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    res = fit_bma_em(Eobs, Esim, max_iter=500, tol=1e-7, verbose=False)\n",
    "    w_ic_ym  = res['weights'][0]\n",
    "    w_ic_am  = res['weights'][1]\n",
    "    w_ic_dm  = res['weights'][2]\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_BMA_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5bdfbb",
   "metadata": {},
   "source": [
    "# GRC方法计算多模型平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38fbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "def grc_weights(X, y, ridge=1e-8):\n",
    "    T, M = X.shape\n",
    "    def obj(w):\n",
    "        preds = X.dot(w)\n",
    "        return np.sum((y - preds)**2) + ridge * np.sum(w**2)\n",
    "    w0 = np.ones(M) / M\n",
    "    cons = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1})\n",
    "    bounds = [(0, 1) for _ in range(M)]\n",
    "    res = minimize(obj, w0, bounds=bounds, constraints=cons, method='SLSQP', options={'ftol':1e-12, 'maxiter':1000})\n",
    "    if not res.success:\n",
    "        w = np.copy(w0)\n",
    "        lr = 0.01\n",
    "        for it in range(10000):\n",
    "            grad = -2 * X.T.dot(y - X.dot(w)) + 2 * ridge * w\n",
    "            w -= lr * grad\n",
    "            w = np.maximum(w, 0)\n",
    "            s = np.sum(w)\n",
    "            if s == 0:\n",
    "                w = np.ones(M) / M\n",
    "            else:\n",
    "                w = w / s\n",
    "            if np.linalg.norm(grad) * lr < 1e-9:\n",
    "                break\n",
    "        return w, obj(w)\n",
    "    return res.x, res.fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f925d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ce4ff9c9a24ad287e62e81b420b7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grc, objval = grc_weights(Rsim, Robs)\n",
    "    R_grc = Rsim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "    w_ic_gym = weight_grc['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grc, objval = grc_weights(Esim, Eobs)\n",
    "    E_grc = Esim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "    w_ic_gym = weight_grc['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRC.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8893dac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae6ad6ef1d44f6494bc042d69ae71ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grc, objval = grc_weights(Rsim, Robs)\n",
    "    R_grc = Rsim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grc, objval = grc_weights(Esim, Eobs)\n",
    "    E_grc = Esim.dot(weights_grc)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_grc = dict(zip(model_names, weights_grc.tolist()))\n",
    "    w_ic_ym  = weight_grc['YM']\n",
    "    w_ic_am  = weight_grc['AM']\n",
    "    w_ic_dm  = weight_grc['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRC_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22000ff4",
   "metadata": {},
   "source": [
    "# GRB方法计算多模型平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d258a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def grb_weights(X, y):\n",
    "    # 确保输入是 numpy 数组\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    \n",
    "    # 如果 y 是一维的，转为列向量\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    # 最小二乘估计\n",
    "    XtX = X.T @ X\n",
    "    Xty = X.T @ y\n",
    "    weights = np.linalg.pinv(XtX) @ Xty  # 用伪逆更稳健\n",
    "    \n",
    "    # 转为行向量\n",
    "    weights = weights.flatten()\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1d7255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904bafe993af4450ac2af4712beae162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grb = grb_weights(Rsim, Robs)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "    w_ic_gym = weight_GRB['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grb = grb_weights(Esim, Eobs)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "    w_ic_gym = weight_GRB['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRB.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234f2842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1d938c1734349e0834c54a5e5ded748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    weights_grb = grb_weights(Rsim, Robs)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    weights_grb = grb_weights(Esim, Eobs)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRB = dict(zip(model_names, weights_grb))\n",
    "    w_ic_ym  = weight_GRB['YM']\n",
    "    w_ic_am  = weight_GRB['AM']\n",
    "    w_ic_dm  = weight_GRB['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRB_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57097a3a",
   "metadata": {},
   "source": [
    "# GRA方法计算多模型平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7183e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gra_weights(X, y):\n",
    "    X_ext = np.column_stack([np.ones(X.shape[0]), X])  # 加一列截距项\n",
    "    beta = np.linalg.lstsq(X_ext, y, rcond=None)[0]\n",
    "    a_hat = beta[0]\n",
    "    w_hat = beta[1:]\n",
    "    y_pred = X_ext.dot(beta)\n",
    "    sse = np.sum((y - y_pred) ** 2)\n",
    "    return a_hat, w_hat, y_pred, sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c5f9021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395e690f9e41482ba28ac7d9309a0436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_vars = ['r_w', 'e_w']\n",
    "models = ['YM', 'AM', 'DM', 'GYM']\n",
    "results = {f\"{var}_{model}\": np.full(2003, np.nan) for var in result_vars for model in models}\n",
    "\n",
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    x_cali_g, y_cali_g, _, _, x_esim_g, y_esim_g = get_data_distributed(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "    r_sim_gym, _ = GmYWBM_RE(x_cali_g, params_GYM.loc[basin].values)\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "    _, e_sim_gym = GmYWBM_RE(x_esim_g, params_GYM.loc[basin].values)\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "    r_sim_gym = r_sim_gym[y_mask]\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "    e_sim_gym = e_sim_gym[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm, r_sim_gym]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm, e_sim_gym]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    a_gra, weights_gra, R_gra, sse = gra_weights(Rsim, Robs)\n",
    "    R_GRA = a_gra + Rsim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "    w_ic_gym = weight_GRA['GYM']\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "    results['r_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    a_gra, weights_gra, E_gra, sse = gra_weights(Esim, Eobs)\n",
    "    E_GRA = a_gra + Esim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM','GYM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "    w_ic_gym = weight_GRA['GYM']\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "    results['e_w_GYM'][b] = w_ic_gym\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRA.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e200457b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ddf5a071e24d9f991f946012ad001a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2003 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for b in trange(len(basin_list)):\n",
    "    basin = str(basin_list[b])\n",
    "    # print(f\"Working: {b+1}. {basin}\")\n",
    "    ## 流域数据读取\n",
    "    # 径流模拟数据\n",
    "    x_cali_l, y_cali_l, _, _, x_esim_l, y_esim_l = get_data_lumped(basin, b)\n",
    "    # 径流模拟\n",
    "    r_sim_ym, _  = mYWBMnlS_RE(x_cali_l, params_YM.loc[basin].values)\n",
    "    r_sim_am, _  = abcdnlS_RE(x_cali_l, params_AM.loc[basin].values)\n",
    "    r_sim_dm, _  = DWBMnlS_RE(x_cali_l, params_DM.loc[basin].values)\n",
    "\n",
    "    _, e_sim_ym  = mYWBMnlS_RE(x_esim_l, params_YM.loc[basin].values)\n",
    "    _, e_sim_am  = abcdnlS_RE(x_esim_l, params_AM.loc[basin].values)\n",
    "    _, e_sim_dm  = DWBMnlS_RE(x_esim_l, params_DM.loc[basin].values)\n",
    "\n",
    "    y_mask = ~np.isnan(y_cali_l) & ~np.isnan(r_sim_ym) & ~np.isnan(r_sim_am) & ~np.isnan(r_sim_dm)\n",
    "    y_cali_l  = y_cali_l[y_mask]\n",
    "    r_sim_ym  = r_sim_ym[y_mask]\n",
    "    r_sim_am  = r_sim_am[y_mask]\n",
    "    r_sim_dm  = r_sim_dm[y_mask]\n",
    "\n",
    "    y_mask = ~np.isnan(y_esim_l) & ~np.isnan(e_sim_ym) & ~np.isnan(e_sim_am) & ~np.isnan(e_sim_dm)\n",
    "    y_esim_l  = y_esim_l[y_mask]\n",
    "    e_sim_ym  = e_sim_ym[y_mask]\n",
    "    e_sim_am  = e_sim_am[y_mask]\n",
    "    e_sim_dm  = e_sim_dm[y_mask]\n",
    "\n",
    "    Rsim = np.vstack([r_sim_ym, r_sim_am, r_sim_dm]).T\n",
    "    Esim = np.vstack([e_sim_ym, e_sim_am, e_sim_dm]).T\n",
    "\n",
    "    Rsim = np.where(np.isinf(Rsim), np.nan, Rsim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Rsim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Rsim))\n",
    "    Rsim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "    Esim = np.where(np.isinf(Esim), np.nan, Esim)  # 把 inf 换成 nan\n",
    "    row_means = np.nanmean(Esim, axis=1)  # 每行的非nan平均\n",
    "    inds = np.where(np.isnan(Esim))\n",
    "    Esim[inds] = np.take(row_means, inds[0])  # 用对应行的均值替换nan\n",
    "\n",
    "    Robs = y_cali_l\n",
    "    a_gra, weights_gra, R_gra, sse = gra_weights(Rsim, Robs)\n",
    "    R_GRA = a_gra + Rsim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "\n",
    "    results['r_w_YM'][b]  = w_ic_ym\n",
    "    results['r_w_AM'][b]  = w_ic_am\n",
    "    results['r_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "    Eobs = y_esim_l\n",
    "    a_gra, weights_gra, E_gra, sse = gra_weights(Esim, Eobs)\n",
    "    E_GRA = a_gra + Esim.dot(weights_gra)\n",
    "    model_names = ['YM','AM','DM']\n",
    "    weight_GRA = dict(zip(model_names, weights_gra.tolist()))\n",
    "    w_ic_ym  = weight_GRA['YM']\n",
    "    w_ic_am  = weight_GRA['AM']\n",
    "    w_ic_dm  = weight_GRA['DM']\n",
    "\n",
    "    results['e_w_YM'][b]  = w_ic_ym\n",
    "    results['e_w_AM'][b]  = w_ic_am\n",
    "    results['e_w_DM'][b]  = w_ic_dm\n",
    "\n",
    "df_results = pd.DataFrame(results, index=basin_list)\n",
    "df_results.index.name = 'stat_num'\n",
    "df_results.to_csv(\"../../Results/Weighted_Average/Weighted_Average_Results_GRA_3M.txt\", sep = '\\t', header=True, float_format=\"%.3f\", index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
